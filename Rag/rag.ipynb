{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\n…\\n\\nIt will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken from our hearts.\\n\\nWe have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.\\n\\nIt is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our hearts—for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.\\n\\nTo such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.', metadata={'source': 'speech.txt'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader=TextLoader(\"speech.txt\")\n",
    "text_document=loader.load()\n",
    "print(text_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import  load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"cohere_api_key\"]=os.getenv(\"cohere_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "loader=WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"post-title\",'post-content','post-header')\n",
    "                                                           )))\n",
    "text_document=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(\"CAPTCHATypesandBreaking TechniquesDesign Issues.pdf\")\n",
    "text_document=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues,\\nChallenges, and Future Research Directions\\nNOSHINA TARIQ, Department of Avionics Engineering, Air University, Pakistan\\nFARRUKH ASLAM KHAN∗,Center of Excellence in Information Assurance, King Saud University, Saudi\\nArabia\\nSYED ATIF MOQURRAB, School of Computing, Gachon University, South Korea\\nGAUTAM SRIVASTAVA, Brandon University, Canada\\nThe proliferation of the Internet and mobile devices has resulted in malicious bots’ access to genuine resources\\nand data. Bots may instigate phishing, unauthorized access, denial-of-service, and spoofing attacks, to mention\\na few. Authentication and testing mechanisms to verify the end-users and prohibit malicious programs from\\ninfiltrating the services and data are strong defense systems against malicious bots. Completely Automated\\nPublic Turing test to tell Computers and Humans Apart (CAPTCHA) is an authentication process to confirm\\nthat the user is a human; hence, access is granted. This paper provides an in-depth survey on CAPTCHAs and\\nfocuses on two main things: (1) a detailed discussion on various CAPTCHA types along with their advantages,\\ndisadvantages, and design recommendations, and (2) an in-depth analysis of different CAPTCHA breaking\\ntechniques. The survey is based on over two hundred studies on the subject matter conducted since 2003 to\\ndate. The analysis reinforces the need to design more attack-resistant CAPTCHAs while keeping their usability\\nintact. The paper also highlights the design challenges and open issues related to CAPTCHAs. Furthermore, it\\nalso provides useful recommendations for breaking CAPTCHAs.\\nCCS Concepts: •CAPTCHA ;•CAPTCHA types ;•CAPTCHA breaking techniques ;\\nACM Reference Format:\\nNoshina Tariq, Farrukh Aslam Khan, Syed Atif Moqurrab, and Gautam Srivastava. 2023. CAPTCHA Types\\nand Breaking Techniques: Design Issues, Challenges, and Future Research Directions. ACM Comput. Surv. 00,\\n0, Article 000 (February 2023), 46 pages. https://doi.org/10.1145/1122445.1122456\\n1 INTRODUCTION\\nThe Internet is a primary mode of communication in the modern age of the Internet of Things\\n(IoT) [ 1]. The availability of a diverse range of mobile devices and more affordable high-speed data\\nsubscriptions boosted consumers’ interest in Internet use. From its inception, Internet security\\nhas been the primary concern of web developers. As the Internet continues to grow for providing\\nvarious websites, services, and blogs likewise grow. Today’s websites are dedicated to the public,\\ntransportation, entertainment, financial services, food items, healthcare, and hotel reservations, to\\nmention a few. In this regard, the growing user base also necessitates the deployment of high-end\\ncomputing power at the websites [ 2]. However, these high-end processors are rendered ineffective\\nAuthors’ addresses: Noshina Tariq, noshina.tariq@mail.au.edu.pkDepartment of Avionics Engineering,, Air University,\\nService Road E-9/E-8, Islamabad, Pakistan; Farrukh Aslam KhanCenter of Excellence in Information Assurance,, King\\nSaud University, P.O. Box 92144, Riyadh, 11653, Saudi Arabia, fakhan@ksu.edu.sa; Syed Atif Moqurrab, atif@gachon.ac.kr,\\nSchool of Computing, Gachon University, 1342, Seongnam-daero, Sujeong-gu, Seongnam-si, 13120, Seongnam, South Korea;\\nGautam Srivastava, srivastavag@brandonu.ca, Brandon University, Brandon, MB R7A 6A9,, Brandon, Canada.\\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\\nthe full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.\\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\\n©2018 Association for Computing Machinery.\\n0360-0300/2023/2-ART000 $15.00\\nhttps://doi.org/10.1145/1122445.1122456\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.arXiv:2307.10239v1  [cs.CR]  16 Jul 2023', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 0}),\n",
       " Document(page_content='000:2 Noshina et al.\\nif the high-end automated device targets them. Therefore, the defense against such automated\\nattacks is imperative. However in an open-access network environment, the ubiquity of the Internet\\nis encouraging security threats for individuals gaining network access. It is not an easy task for the\\nweb service providers to understand whether a certain application is accessed by a bot or a human\\nuser [3].\\nNonetheless, bot programs are extremely useful to carry out cyclic and time intense operations.\\nOppressed for malevolent work, bot programs have human behavior reproduction ability. Therefore,\\nsecurity is the main ingredient in a reliable communication interface [ 4]. It points to sheltering and\\nprotecting networks from vicious attacks. Introducing security services in computer networks seeks\\nto deliver convenient, reliable, and classified application environment [ 5] [6] [7], and [ 8]. There is\\nvarious computer exploitation, including worms, spoofing, viruses, and network crossing. Moreover,\\nother kinds of attacks would be unauthorized ones: covert channels, Denial of Services (DoS), and\\ncompromised and malicious nodes, to name a few [ 9]. A majority of Completely Automated Public\\nTurning test to tell Computers and Humans Apart (CAPTCHA) systems have been proposed that\\nuse various features, such as characters, images, and audio, to generate challenges that effectively\\nprevent automated bots. However, recent advancements in Artificial Intelligence (AI) in general\\nand Computer Vision (CV) in particular have greatly improved automated systems’ ability to solve\\nsuch tasks [ 10,11]. As a consequence, almost all conventional CAPTCHA systems have been\\ncompromised. Hence, there needs to have an in-depth analysis of CAPTCHA formation and its\\nbreaking techniques to make them more robust and usable.\\nCAPTCHA (AKA Human Interaction Proof (HIP)) is introduced to mitigate spurious network\\nresources access [ 12–14]. It was coined in 2000 by Luis Von Ahn at Carnegie Mellon University [ 15].\\nIt is a protection method for avoiding electronic registration, spam, and harmful bot applications.\\nThey are well-known for providing practical security by differentiating humans from computers; for\\nexample, lock-free Email services, shielding online polling against online voting bots, or malicious\\nemail sign-ups. They are effective in handling email worms and spam and in preventing dictionary-\\nbased password attacks [ 16]. In general, a test that is simple for people to solve and difficult for\\ncomputers is generated and evaluated. It is deemed successful if its success rate in human solutions\\nis greater than 90%, and computers reach just a success rate of less than 1% [ 17]. A strong CAPTCHA\\nis generally known, not only functional but stable. It is continuously evolving technology and\\nis increasingly growing in literature and practice. The emerging literature references must be\\nsummarised, and a more comprehensive analysis of CAPTCHAs must be carried out.\\nVarious models have appeared after CAPTCHAs have been produced. Among different types of\\nCAPTCHAs, text-based CAPTCHAs are widely used [ 4], Fig. 1 shows some examples of text-based\\nCAPTCHAs [ 18]. However, researchers attack CAPTCHAs to identify which interface features\\nare good for its protection to make it resilient. This paper presents an in-depth and exhaustive\\nstudy of different CAPTCHA schemes and their breaking techniques proposed from 2003 to date.\\nWe analyzed its types regarding their strengths and weaknesses. This paper also presents the\\nmajor applications of CAPTCHAs. We also studied several CAPTCHA breaking techniques, which\\nare discussed later in the paper. Based on our comprehensive study and analysis, we classified\\nCAPTCHA types into OCR and non-OCR categories presented in Section 4. We also classified\\nCAPTCHA breaking techniques into four categories discussed in Section 6. Later, we present several\\nchallenges and open issues related to CAPTCHA designs and breaking.\\nThis paper has the following major contributions:\\n(1)The classifications (taxonomies) of CAPTCHA types and breaking techniques is presented\\nand thoroughly analyzed.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 1}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:3\\nFig. 1. Different kinds of text CAPTCHAs.\\n(2)An analysis of state-of-the-art CAPTCHA survey papers (for both construction and breaking)\\nis done, highlighting their contributions and missing research areas in the said domain.\\n(3)CAPTCHA practices and applications are discussed, helping readers better understanding\\nthe areas where CAPTCHAs may be useful.\\n(4)Based on CAPTCHA formation, exhaustive state-of-the-art study and analysis are presented.\\nIn line with CAPTCHA types, advantages and disadvantages accordant with the proposed\\ntaxonomies are also provided for engineering better designs.\\n(5)Based on CAPTCHA breaking techniques, a comprehensive state-of-the-art study and analysis\\nare presented to fix the loopholes in CAPTCHA designs that may be exploited by the attackers.\\n(6)In-depth analysis and future prospects of design issues and challenges are imparted encom-\\npassing a prolific discussion on CAPTCHA sturdiness and usability.\\nIn this survey paper, Section 2 presents related work that provides a comparison among state-\\nof-the-art survey. In Section 3, important CAPTCHA application areas are discussed. Section 4\\npresents different CAPTCHA techniques based on their formation and design. Challenges and\\nopen issues in CAPTCHAs designs are discussed in Section 5. Section 6 represents the survey of\\nstate-of-the-art CAPTCHA breaking algorithms. Section 7 presents a productive discussion on\\nCAPTCHA robustness and usability along with the challenges and open issues, and Section 8 gives\\nthe conclusion and future directions.\\n2 RELATED SURVEYS\\nThis section briefly discusses state-of-the-art surveys from 2010 to date. Table 1 presents a compar-\\nison between state-of-the-art and this paper. We compared contributions and the subject matter,\\nsuch as the survey about CAPTCHA types, attacks on CAPTCHAs or both. It is also investigated\\nthat the survey has proposed any taxonomy of CAPTCHA types or its breaking techniques or\\nnot. That helps readers to understand the subject matter in a modular way. It is also essential\\nthat a survey discusses challenges and open issues associated with the subject matter from our\\nperspective. That helps the readers to find the gaps and future research directions.\\nMagdy et al. [ 21] presented a survey on CAPTCHA types and breaking techniques. Though they\\nhave discussed its different types and limited usability issues; however, the survey is not compre-\\nhensive. Kumar et al. [ 22] presented a systematic survey on CAPTCHAs. This paper encompasses\\na good discussion of different CAPTCHAs and their breaking. However, types and attacks are not\\nclassified as the techniques used in their breaking. Moreover, it does not discuss challenges and open\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 2}),\n",
       " Document(page_content='000:4 Noshina et al.\\nTable 1. Comparison among state-of-the-art surveys\\nRef. Year Type-based Attack-based Applications Taxonomy Challenges & Open issues Recommendations\\nThis paper 2023 ✓ ✓ ✓ ✓ ✓ ✓\\n[19] 2023 ✓××× × ×\\n[20] 2022 ✓ ✓ ✓× × ×\\n[21] 2021 ✓ ✓× ✓ × ×\\n[22] 2021 ✓ ✓ ✓× × ×\\n[23] 2021× ✓×× × ×\\n[24] 2021 ✓× ✓× × ×\\n[25] 2019 ✓ ✓×× ✓ ×\\n[26] 2020 ✓ ✓×× × ×\\n[27] 2020× ✓×× × ×\\n[28] 2016 ✓× ✓× × ×\\n[29] 2018 ✓××× × ×\\n[30] 2018 ✓ ✓×× × ×\\n[31] 2013 ✓ ✓×× ✓ ×\\n[32] 2015 ✓××× × ×\\n[33] 2010 ✓××× × ×\\n[34] 2011 ✓ ✓×× × ×\\nissues in CAPTCHA designing and breaking. However, our paper provides a more comprehensive\\nsurvey on CAPTCHA types and breaking techniques. Still, it also discusses challenges and open\\nissues in this regard, along with the recommendations for designing and breaking CAPTCHAs.\\nZhang et al. [ 25] discuss the advancements made scientifically and technologically on CAPTCHAs’\\ndesign and attacks. They discussed the usability, robustness, and limitations of different types of\\nCAPTCHAs. Besides, the attack techniques and differences between the formation of CAPTCHAs\\nare categorically debated. This paper discusses recommendations for future studies and suggests\\nseveral issues that require extra analysis. However, a taxonomy of types and breaking techniques\\nis not presented.\\nThe CAPTCHA usability and its progression technology are also assessed in [ 26]. It examines\\nthe CAPTCHA mechanisms from usability and security aspects, unlike other studies that have been\\ndone on it. The introduction of new CAPTCHA formats (game CAPTCHA) and attacking methods\\n(deep learning-based attacking) are also included in this paper. However, they do not present a\\ntaxonomy and a discussion about challenges and open issues. Besides, [ 27] carries out methodical\\ninvestigation and categorization. The study is based on the ultramodern ML-based method for\\nself-operating text-based CAPTCHA breaking issues. An investigation into the present status and\\nrobustness of text-based CAPTCHA is also presented. The present-day Internet users use it to\\ncounter ML-based automated breaking tools in this paper. This literature also recommends that\\nML-based as a breaking tool is very efficacious because of its speed, precision, and reverie in the\\nCAPTCHA solution. This paper encourages combatting the issues associated with current internet\\nservices and ML-based methods; a reverse Turing test is encouraged in this paper. Reverse Turing\\nsystems are recommended because they offer less stress to human users and give computer/robots\\nchallenging problems. However, the paper does not present a taxonomy of the CAPTCHA types or\\ntheir breaking techniques. It also lacks in discussing challenges and open issues in this regard.\\nCAPTCHA types, their usability, and deficiencies are discussed in [ 28]. However, this survey\\nfocuses on CAPTCHA types only. Moreover, it does not discuss attacks made on CAPTCHAs. It\\nalso does not present a taxonomy and the challenges and open issues associated with CAPTCHA\\ntypes. [29] compares CAPTCHA and completely automated public physical test to tell computers\\nand humans apart (CAPPCHA). CAPPCHA and CAPTCHA are alike because they are both used\\nto protect websites from abusive automated programs. As discussed in this paper, CAPPCHA\\nimproves the authentication technique required for mobile devices. Besides, a proof of concept\\nis also provided. However, an extensive analysis of the subject must be carried out to confirm\\nthe efficiency of CAPPCHA. Therefore, this paper aims to thoroughly investigate CAPTCHA’s\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 3}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:5\\nofficiousness and its usability involving several human users. However, this paper also does not\\ntalk about CAPTCHA breaking techniques, taxonomy, and challenges.\\nIn [30], keywords, such as; login, cart, registration, account, post, auth, join, register, sign,\\npassword, and subscribe, were used by a personally web designed crawler. The crawler makes use\\nof a beautiful soup library to investigate 30,000 websites and check if they use CAPTCHA to protect\\ntheir URLs. This paper also examines and categorizes CAPTCHA as regards its limitations. Out of\\n30,000 web pages, only 10,017 uses CAPTCHA. According to the facts provided by this survey, the\\nmost used CAPTCHA includes; text/image-based CAPTCHA, reCAPTCHA, text-based CAPTCHA,\\nmath, slider, FunCAPTCHA, custom, and audio-based CAPTCHA. However, taxonomy and open\\nissues are not addressed in this paper.\\n[31] discusses three essential things. They include; recent CAPTCHAs and associative attacks,\\nthe inquiry into the vigor and usefulness of recently introduced CAPTCHAs, and propose new\\ntechniques to improve recently introduced CAPTCHAs. However, the paper does not suggest a\\ntaxonomy. [ 32] explores substitutes of CAPTCHA, usability, and services provide researchers with\\nenough information so that new techniques and solutions can be suggested. Thus far, the positive\\nstrides made in CAPTCHA advancements, various CAPTCHAs substitutes, were categorized,\\nevaluated, and compared with their shortcomings. Solutions to the shortcoming were also proposed.\\nHowever, CAPTCHA breaking is out of the scope of this paper. Besides, there is no proposed\\ntaxonomy, and no discussion on open issues are discussed either.\\nFrom the human standpoint, [ 33] extensively reviews CAPTCHAs to gauge how much an average\\nuser is affected by CAPTCHA. However, this paper focuses only on CAPTCHA types. There is no\\ntaxonomy presented. There is no discussion on open issues and challenges presented in the paper.\\nSimilarly, Bandy et al. [ 34] presented a classification of CAPTCHAs and compared its different kinds.\\nThe CAPTCHAs are classified and compared as regards their usability and security. Conventional\\nmethods for generating and breaking text and image-based CAPTCHA are also introduced. Lastly,\\nthis paper recommends various ways to enhance vigor, usability and to tackle security issues.\\nHowever, taxonomy and open issues are not discussed.\\n3 CAPTCHA PRACTICES\\nThere are several CAPTCHA practices and applications; this section highlights some of the most\\ncommon practised CAPTCHA applications below:\\n3.1 Mitigating e-mail (address) security and spams\\nAhn et al. [ 35] described how web scrapers (programs that extract data from websites) might\\nbe prevented from obtaining users’ e-mail addresses by requiring them to answer a CAPTCHA\\nprior to revealing their e-mail addresses. It may also be used for the prohibition on the use of fake\\ne-mail addresses. Most businesses offer complimentary e-mail services in today’s information era.\\nThey are the targeted victims of bot assaults. Numerous businesses adopt such methods to obtain\\ncomplimentary e-mail addresses to distribute spam. A most effective yet simplest way of avoiding\\nunwanted bot assaults is to utilise CAPTCHA-based security. Pope and Kaur [ 36] highlighted that\\nthe majority of e-mail providers had implemented such an approach.\\n3.2 Phishing Attacks Prevention\\nPhishing is a technique used by unethical attackers (e.g., hackers and crackers) to gain access\\nto online banking, e-voting, social media, and e-mail accounts by displaying a similar false web\\npage to the account owner [ 37] [15]. For instance, these attackers send a link to certain targeted\\naccount holders through the e-mail accounts, and by clicking the link, they submit sensitive details,\\nsuch as usernames and passwords. It results in the loss of confidential information such as official\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 4}),\n",
       " Document(page_content='000:6 Noshina et al.\\nrecords or project bids. Phishing attackers collect bank information such as usernames, passwords,\\nand credit/debit card information. Certain websites are legitimate financial websites, and some\\nare duped into providing personal and private web to these false websites. These attackers do\\nnot utilise their method to break internet accounts, which makes the tracking very challenging.\\nAdditionally, cyber law is not sufficient to prosecute such unethical hackers [ 22]. Under such cases,\\ncertain countermeasures must be adopted in conjunction with a strong authentication process.\\nHence, CAPTCHA is inevitable in both bot and phishing attack scenarios.\\n3.3 Banning robots from playing games\\nUsing the CAPTCHA is easier than previously thought to restrict online bot gaming. It is extremely\\nsimple to keep robots and computers from playing online games, as found by [37], [38], and [39].\\n3.4 Ensuring a strong internet protection\\nA recent online paper outlined the theory of dictionary attack, which aims to find the passphrase or\\npassword of an authentication system by accessing probable alternatives. CAPTCHA is particularly\\nefficient in protecting against such dictionary assaults in these types of circumstances, according\\nto [40], [41], and [42].\\n3.5 A way to handle worms and spam\\nCAPTCHA is used to combat worms and spam and accept mail only if no computer program is\\npresent, proving that humans are behind it [21], [43], and [44].\\n3.6 Stronger password security\\nAttempting to enter the password after too many incorrect tries may result in an account being\\nlocked, but this is not a superior approach. Ahn et al. [ 45] claim that if a computer program tries to\\ncomplete a task, it may be overridden by requiring the user to input a CAPTCHA to demonstrate\\nthat it is a person and not a computer program.\\n3.7 A search engine bot’s barrier\\nPope and Kaur [ 36] and Kim and Luke [ 46] pointed out that if a business wants its web pages to\\nremain undisturbed, CAPTCHA will help to block computers from indexing the sites.\\n3.8 Keep automatic online polls to a minimum\\nCAPTCHA may also be used to prevent a computer program from voting in online polls. The claims\\nof [45] and [ 36] asserted that even while it cannot be used to prevent a person from voting more\\nthan once, it cannot be used to allow them to vote more than once either.\\n3.9 A Rejecting Shopping Agent Solution\\nThis kind of software is quite popular today: You may build one that provides you with a full\\ncost comparison from many comparable websites, for example, trivago or makemytrip [ 22]. Since\\nthe customer cannot view all the ads from these online shops, the online stores lose out. Reject-\\ning this kind of program from disclosing pricing information is extremely successful using the\\nCAPTCHA [47].\\n4 CLASSIFICATION OF CAPTCHAS BASED ON THEIR TYPES\\nThe CAPTCHA schemes may be broadly classified into Optical Character Reader (OCR) and non-\\nOCR CAPTCHA formations. They can further be classified into different types, as shown in Fig. 2.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 5}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:7\\nFig. 2. The proposed taxonomy of CAPTCHA types.\\nThis section presents different CAPTCHA schemes classified based on OCR-based and Non-OCR\\nCAPTCHAs, along with each approach’s pros and cons.\\n4.1 OCR-Based CAPTCHA Schemes\\nThis section presents the most commonly OCR-based CAPTCHA schemes.\\n4.1.1 Text-based CAPTCHAs. In 1997, the first bot attack was made on Alta Vista that submitted\\nautomated URLs. Therefore, distorted arbitrary text CAPTCHAs were generated by Andrei Border\\nto deter bots [48].\\nFig. 3. Text CAPTCHAs at CAPTCHAservice.org.\\nText-based CAPTCHAs are categorized as reading-based CAPTCHAs. The user reads a text made\\nup using only letters or a random combination of numbers or letters and inputs them into a given\\nbox in the same sequence [ 49]. It is quite troublesome for a computerized program to read twisted\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 6}),\n",
       " Document(page_content='000:8 Noshina et al.\\nletters or numbers from clutter. This clutter could consist of anything like a grid, noise, shapes,\\nlines, hues, shades, or contrasting colors. These CAPTCHAs are broadly used by many websites\\nsuch as Google, rapid-share, MSN, Yahoo, YouTube, and Badongo. An example of a text-based\\nCAPTCHA is shown in Fig. 3 [50].\\nFig. 4. EZ-Gimpy challenge image.\\nFig. 5. Gimpy-r challenge image.\\nGimpy-r and EZ-Gimpy are a few examples of a text-based CAPTCHA, as shown in Fig. 4\\nand 5 [ 51]. In Gimpy, an image is shown with the variegated text, and the user has to input three\\ndifferent texts or words by looking at them [ 52]. reCAPTCHA is another severe form of a text-based\\nCAPTCHA. Text-based CAPTCHA’s benefit lies in its formation, where simple 4-8 letter words\\nor arbitrarily written letters or numbers may be used. It is not very complicated for a user to\\nrecognize; however, it might not be the case as development has been done to make them robust.\\nThe deformation and noise are enhanced to make it attack-resistant, making it difficult for users to\\nunderstand and recognize the letters. People with visual restraints may also find it cumbersome\\nand fail. Moreover, if dictionary-based words are used, a huge database is required. They are also\\nvulnerable to various attacks [ 53], [54], [55]. Most of the attacks on text-based CAPTCHAs are\\nbased on OCR techniques. Therefore, the designing of a robust text CAPTCHA is inevitable [ 56].\\nSimilarly, Shao et al. [ 57] proposed an attack-resistant text based-CAPTCHA using adversarial\\nexamples.\\n4.1.2 3D CAPTCHAs. Many websites have employed the 2D text CAPTCHAs to protect themselves\\nfrom automated bots. These CAPTCHAs are designed using random characters, symbols, and\\nnumbers in a 2D space format, as shown in Fig. 1 [ 58]. The most significant disadvantage with\\nthese approaches is that they can easily be cracked through automated offline post-processing\\nattacks [ 58]. These approaches work by segmenting the whole CAPTCHA and then recognize each\\ncharacter individually. Many attempts have been made to improve security by including dots and\\nlines across the CAPTCHAs. Deep Neural Networks (DNNs) for cracking the 2D CAPTCHAs have\\nposed severe security threats with an accuracy of 83% [ 59]. The use of 2D text CAPTCHAs can\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 7}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:9\\neasily be compromised with improved OCR technology. [ 60] is a new type of text-based CAPTCHA\\nknown as DotCHA, which depends on human interaction. In this approach, the user has to rotate\\nthe 3D text model to identify the correct letters. In nature, the 3D text model is the twisted and\\nsequential 3D text having a centre pivot axis, which depicts different letters upon rotation. This\\ntype of CAPTCHA is protected from segmentation attacks. It is composed of different spheres\\nof each letter, i.e., it is a scatter-type CAPTCHA. This type of CAPTCHA is also protected from\\nmachine Learning (ML) attacks due to its unique working way.\\nFig. 6. A DotCHA image.\\n4.1.3 Hand-written CAPTCHAs. Lin and Wan [ 61] gave an idea of a synthesized form of hand-\\nwritten CAPTCHAs. GUI interface to accumulate and build samples. Mori et al. [ 62] used a method\\nthat produces samples of naturally written characters. Parvez et al. [ 63] proposed an Arabic hand-\\nwritten CAPTCHA scheme based on the ’segmentation-validation’ generation. Recently, another\\nexample is presented inusing Hindi language. One such example is shown in Fig. 7 [64].\\nFig. 7. Showing synthesized handwritten CAPTCHA.\\nOne main advantage of hand-written CAPTCHA is that it is challenging for a computer to apply\\ntechniques like segmentation, making it grueling to recognize. However, collecting samples of\\nhand-written words is a real problem. The size of the collection and maintaining the dataset is a\\nlarge problem. It is also vulnerable to attacks, such as brute force dictionary attacks. Another issue\\nwith hand-written CAPTCHAs is the cursive writing that can also make it a little problematic for\\nhumans to identify [65].\\n4.2 Hollow CAPTCHA\\nAnother newly emerged text-based CAPTCHA is hollow. These CAPTCHAs are deployed by many\\nwell-known websites like Yahoo!, Tencent, Sina, China Mobile, and Baidu. It uses contour lines as its‘\\nmain feature in fabricating the connected hollow characters. The main aim of these contour lines is\\nto improve the security and usability of the scheme. The standard segmentation and recognition\\ntechniques fail to break connected characters. Hollow CAPTCHA models come in different designs\\nwith various design features, such as use interference arcs, varied lengths, and thickness of hollow\\nportions and randomly-generated contours. However, too much teeming and overlapping may\\nconfuse character pairs, compromising its usability [66][67], as illustrated in Fig. 8.\\n4.3 Non-OCR CAPTCHAs\\nThis section presents Non-OCR CAPTCHA schemes.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 8}),\n",
       " Document(page_content='000:10 Noshina et al.\\nFig. 8. Showing hollow CAPTCHAs.\\n4.3.1 Image-based CAPTCHAs. Progress made in the making of CAPTCHAs has turned towards\\nimage-based CAPTCHAs [ 68]. The user has to identify and select a specific picture from several\\nlisted images, as shown in Fig. 9 [ 18]. It uses advancements in the field of image identification\\nand blew out the inherent issues of text-based CAPTCHAs. One such example is presented in [ 69]\\nusing adversarial perturbation and they used Convolutional Neural Network (CNN) for its security\\nanalysis.\\nFig. 9. Different image-based challenges.\\nInitially, Chew and Tygar [ 70] used labeled allied images in Google Image Search. After that,\\nAhen and Dabbish [ 35] established labels in \"ESP Games.\" However, these required classes of objects\\nand a substantial database. Similarly, images of Kittens were utilized by Oli Warner [ 71]. Once\\nagain, the issue of a small database size arose. However, playing with pictures is simpler and more\\nefficient as they are less distorted and deformed; hence they are agreeable.\\nAfter that, ASIRRA \"Animal Species Image Recognition for Restricted Access\" [ 72] arrived with a\\nthree million images database prepared by Petfinder.com. This database had two distinctive picture\\ntypes (cats and dogs), which were real and innocuous, as shown in Fig. 11. The test was simple as the\\nuser simply differentiates a cat from the list of dogs. This test provided 99.6% usability relief, which\\nthe user can solve in less than 30 seconds. Compared to other CAPTCHAs, ASIRRA used attractive\\nimages; however, an algorithm and a centralized web server must be generalized and confirmed.\\nPictures require more storage as the database has to be maintained and displayed on-screen. There\\nare many image-based CAPTCHAs found in literature [ 73] [74] [75] [76]. An example is shown in\\nFig. 12. Another approach is presented by Kwon et al.in [ 77]. The same authors proposed another\\nimage-based CAPTCHA [ 78] based on adversarial example processes, such as FGSM, I-FGSM, or\\nDeepFool. Another type of two-way image-based CAPTCHA is proposed in [ 79]. The proposed\\nscheme used a homography transformation to match two given images.\\n4.3.2 Audio CAPTCHAs. Data can be perceived in the sense of visual portrayal as well as in the\\nform of audio [ 80]. However, image-based CAPTCHAs are less preferred over audio CAPTCHAs\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 9}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:11\\nFig. 10. Images with various orientation properties.\\nFig. 11. An ASIRRA challenge.\\nas some visually impaired people also utilize the Internet. Consequently, sound CAPTCHAs were\\ncreated to help visually impaired users [81], [82], [83]. Diverse speakers speak letters or numbers\\nafter a certain time interval. The user inputs the correct number or letter in a file. Automated\\nspeech recognition (ASR) software is utilized for this functionality. Background noise is used to\\nmystify it [ 81]. Audio CAPTCHAs may be made more robust using audio-based watermarking\\ntechniques [84]\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 10}),\n",
       " Document(page_content='000:12 Noshina et al.\\nFig. 12. An example of text CAPTCHA.\\nShahreza et al. [ 85] proposed a non-OCR CAPTCHA for visually impaired users based on Text-\\nTo-Speech (TTS) system to generate a mathematical question, and then converting it to speech.\\nOne advantage of this particular method is that automated software needs to make itself familiar\\nwith speech-based questions. In order to solve the problem and answer the questions, it needs to\\nbe smart enough. One other advantage is that a visually impaired person would not have to input\\nlong words. Just a number as a reply would be enough. Hence, it saves time as it is easy to knob.\\nHaichang et al. [ 86] used waveform diagrams for the spoken phrases or words to help the user.\\nThe phrase or word is arbitrarily made or chosen from different types of books. Such sentences\\nappear on the screen, and the user is asked to speak them out loud. At that point, it is decided that\\nwhether the speaker is a bot or a human. This strategy analyzes sound characteristics and exploits\\nthe discrepancy between a simulated machine speech and humans. It offers a high sanctuary;\\nhowever, this particular scheme’s problem is settling on synthetic sound software. The issue with\\naudio CAPTCHAs is background noise, which might affect the user’s hearing acuity. We may also\\nsay that accent problems may also occur and impact recognition for non-native users. Another issue\\nis that most audio strategies utilize audio files, which determines its span and challenge [86][17].\\nFig. 13. Example of audio CAPTCHA.\\nSimilarly, four different types of audio CAPTCHAs are proposed by Fanelle et al. [ 87] with\\nimproved precision and speed. An example image is shown in Fig. 13. They conducted worldwide\\nexperimentation in three-sessions with 67 PVIs. Shekhar et al. [ 88] proposed a robust CAPTCHA\\nscheme, resistant to Deep Learning (DL) and ML attacks.\\n4.3.3 Collage CAPTCHAs. CAPTCHAs mainly established on Non-OCR methods are the collage\\nCAPTCHAs. It usually has contorted shapes that asks for the user to select a certain one. A certain\\nCollage CAPTCHA was presented by Ritury soni [ 89]. On the left of the screen, the image of objects\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 11}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:13\\nis displayed. However, on the right side, it displays other images with the name of the left image, as\\nshown in Fig. 14. The user selects both the left image and the most appropriate word image from\\nthe right of the screen. The user in the given box would type the name in.Similarly, Shanker et\\nal. [90] introduced another hybrid Collage CAPTCHA to reduce CAPTCHA attacks.\\nFig. 14. A collage challenge.\\nIf text and image-based CAPTCHAs are distorted, they usually displease the user and are open\\nto attacks. The database of various pictures of a Collage CAPTCHA (animals, flags, or humans.)\\nis displayed in different places randomly without overlapping in different places and is used\\nafter minor alternation. This objective approach is to spot the desired picture and then guess is\\ncomplicated for a computer. Identification is not an easy process. The computer must be well-versed\\nwith the picture’s knowledge and shapes. It has to track down the precise position of the picture\\ndisplayed on the screen. Thus, resistance brews against their attacks. Such a method can be carried\\nout on other devices with touch screens. Though it is easy to use, it still requires a database of a\\nfixed amount of pictures that inevitably will be repeated. Another novel collage-based CAPTCHA,\\nSCAPTCHA, is proposed in [ 91]. An example image is shown in Fig. 15. It is based on different\\nartifact segments and associated metadata, such as sizes and positions. However, users need to\\nanswer the questions associated with the CAPTCHA.\\nFig. 15. An example of SCAPTCHA along with a text-based and reCAPTCHA example.\\n4.3.4 Mouse-intrusion CAPTCHAs. Among CAPTCHA breaking schemes, a text-based CAPTCHA\\nbreaking scheme is the most profitable. It is the success rate that is greater than the others. Therefore,\\nthe idea of ’Drag and Drop’ CAPTCHA was introduced by Desai and Patadia [ 92]. Example images\\nare in Fig. 17 and Fig. 18. For such kinds of CAPTCHA, mouse intrusion is mandatory. It follows\\nthe Artificial Intelligence (AI) technique. A simple mouse-intervention CAPTCHA image is shown\\nin Fig. 16 [ 93]. Complicated or intricate types of CAPTCHAs usually use redirection and laundry\\nattacks where the CAPTCHA is diverted to ’human sweatshop’ after which hired humans are used\\nso the computer can solve it [94].\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 12}),\n",
       " Document(page_content='000:14 Noshina et al.\\nFig. 16. Mouse-intervention CAPTCHA.\\nIn [95], another click-based CAPTCHA scheme is brought forth. The mouse clicks help identify\\na human by analyzing the clicking on certain image components [ 96]. It also does that through the\\nprocess of dragging and dropping a letter on the destination. The need for a keyboard in this is\\nnil [96]. According to this approach, the users drag and drop the letters at appropriate place. In\\nthis approach, technological scrutiny is not mandatory that ends in relief for the users [ 97]. ’DND’\\nCAPTCHAs do not require any noise and chaotic backgrounds, making it apt in bandwidth use [ 92].\\nDeveloped in JavaScript, HTML, and Java applets make it comprehensible, easy, and simple to\\ndesign and needless bandwidth. A similar approach is proposed by Shah et al. [98], recently.\\nFig. 17. DND CAPTHA image.\\nFig. 18. DND CAPTCHA right or wrong placed.\\nAnother click-based graphical CAPTCHA is presented in [ 99]. Such CAPTCHAs are vital and\\nrobust [ 92], [97], [100]. However, it requires the user to properly fall through with the order and\\nthe character’s exact destination. Another technique involves displaying a panel of changing colors.\\nThe user, as soon as the green color is shown, has to click the button [ 93]. The mouse is also used\\nin Bongo sentences where the clicks help the user find and then type it in the respective place [ 92].\\nLikewise, game-like CAPTCHA is proposed in [ 101] for intrusion detection providing account\\nauthentication. Based on flash-gaming, another gaming CAPTCHA is proposed in [102].\\n4.3.5 Question-based CAPTCHAs. A new approach uses arithmetic problems by keeping four essen-\\ntial abilities that humans possess [ 103]. This approach involves understanding the question’s text,\\ndisclosing question images, comprehending the problem, and then solving it. The arithmetic prob-\\nlem, to the user, is presented as an image. For example, see 19 [ 104]. Question-based CAPTCHAs are\\nformulated to overcome the limitations of both OCR- and Non-OCR-Based CAPTCHAs [ 104], [105].\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 13}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:15\\nGimpy method [ 106] was introduced in OCR-based CAPTCHA to take any word from the dictionary\\nto use as CAPTCHA. Though, it was not scalable with only 850 words in the dictionary.\\nFig. 19. A sample Question.\\nTo lower the quality of a word to be used as CAPTCHA, a pessimal print method [ 107] was\\nused. However, they are also liable to hacking. The method proposed that in [ 108] would surmount\\nthe problem. This method also makes it easy, so that, non-English speakers can benefit from it.\\nAfter this new approach [ 107], Implicit CAPTCHA [ 108] would not be in use. It is also a very\\ncostly method. To make it hard for computers to be acquainted with the speech, Text-to-Speech\\nmethod [ 109] is used. However, the user has to make certain calculations, which people are not\\nwell-versed with it. This method is used both by the OCR and non-OCR techniques, for a bot has\\nto go through more calculations. At times, the images can be extremely incoherent and can lead to\\nincorrect entries by the users.\\n4.3.6 Video CAPTCHAs. A novel content-oriented video CAPTCHA was enlisted to increase user\\nsecurity from 70% to 90% and reduce attacks with only 2% [ 110]. However, in this approach, video\\nlabeling is required. Every time that a video is uploaded on YouTube, it is usually tagged by it is\\nloaded. Accordingly, every time a user plays the video, they need to type three different words, for\\nthat certain video, to describe the video. A video will be played if any of the three words match\\nthe stored database related to that video. However, the users get irritated due to wrong entries. By\\nensuring the Kerchkhoffs’ Principle, tests are produced and checked automatically. All of the tests\\nneed to be solved with minimal exertions put by humans. Finally, it must be very challenging for\\nthe machine to be algorithmically solved [ 110]. An example of video CAPTCHA is given in Fig. 20.\\nIt must be noted that this examination was conducted on a minimal scale video database; it would\\nbe ineffective to expand its size.\\nFig. 20. An example of video CAPTCHA.\\nThus, for large scale video collection, the results would not be reliable. Video-based CAPTCHA\\nsolutions are discussed in [ 111], where the text is embedded in a matter of seconds of flash video.\\nHowever, the users, even without watching the whole clip, may recognize and remember characters\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 14}),\n",
       " Document(page_content='000:16 Noshina et al.\\ninstantly. Another problem is the equipment and software needed, such as the availability of a flash\\nplayer or a compatible decoder. Therefore, the absence of such facilities can make a video playing a\\nfailure.\\n4.3.7 SKETCHA: A Drawing CAPTCHA. As compared to computers, humans are much better at\\nrecognizing 3D images. A new CAPTCHA called \"sketcha\" was devised by Ross et al. [ 112], with a\\nhuge database to display a 3D image in different rotations, as shown in Fig. 21. To bring it to 90\\ndegrees, the user has to click. It is very accessible and friendly to the user, as a user can comprehend\\ndrawing more than photographs [ 113]. However, overlapping, deformation, or addition of clutter is\\nnot required in the image, which makes a drawing CAPTCHA coherent and apparent. They are\\nmore user-friendly and have no language dependency [ 112]. The 3D approach makes it difficult\\nfor the machine by giving different picture styles [ 114]. Though, to bring the image to 90 degrees,\\nseveral clicks may be needed, as shown in Fig. 10. However to save the images, a database is also\\nrequired.\\nFig. 21. A drawing CAPTCHA.\\n4.3.8 Game CAPTCHAs. CAPTCHAs are mainly seen in the form of various numbers, letters, and\\na variety of pictures. The core reason for CAPTCHAs appearance on screen is to ward off users\\nfrom bot programs. Not only do suspicious users get this unrelenting task of solving a CAPTCHA,\\nbut the genuine users also receive them. Judging this uncomfortably from the user end, Chein-Ju et\\nal. [115] came up with a great initiative, namely \"DevilType.\" The maximum numbers of devils are\\noverthrown by using CAPTCHA tests, as shown in image Fig. 22 and 23.\\nFig. 22. A CAPTCHA is attached to each devil.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 15}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:17\\nFig. 23. The devil moves from upside to downside.\\nUltimately this effective strategy helped to get exceptionally credible experiments that gave\\npositive results. This technique owns two integral benefits, i.e., human’s entertainment and playing\\nbecome meaningful. Secondly, the game programmers take leverage when the game logo is displayed\\nseveral times. The CAPTCHA is further segregated into different levels for users to choose from\\nbased on their convenience. In order to make CAPTCHA look a little more complicated and\\nintrigued, more detail is added. It may be fun, however, at the same time, strenuous as well. Manar\\net al. [ 116] proposed a relay attack-resistant Dynamic Cognitive Game (DCG) CAPTCHA. It had\\nsimple moving objects. The user plays an object matching game to pass the test, as shown in Fig. 24\\nand 25.\\nFig. 24. An example of parking games.\\nFig. 25. An example of ships games.\\nAldwairi et al. [ 102] proposes another CAPTCHA, as shown in Fig. 26. It is a flash-based\\nCAPTCHA that is naive and easy to solve yet with the least chances of errors. It can be solved\\nin the shortest time with easy recall capabilities. However, one needs to have technical skills to\\nattempt the test.\\n4.3.9 Hybrid CAPTCHA schemes. This section presents different CAPTCHA approaches based on\\nmixed-use formations, such as text and audio, text and multimedia, and special purpose CAPTCHA\\nschemes. Some examples of hybrid CAPTCHA may be found in [ 117], [118], and [ 119]. A taxonomy\\nof hybrid CAPTCHA scheme is shown in Fig. 27 and the types are discussed below:\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 16}),\n",
       " Document(page_content='000:18 Noshina et al.\\nFig. 26. Flash-Based Gaming CAPTCHA.\\nFig. 27. A taxonomy of Hybrid CAPTCHA schemes.\\n-CAPTCHAs as Public key: All types of CAPTCHAs, whether OCR or non-OCR, are used for\\nbot attack prevention. In Man-in-the-Middle (MitM) attack situation, they fail in securing the\\nresources. Keeping such scenarios in mind, public-key embedded CAPTCHAs are introduced\\nby Samir Saklikar [ 120]. To ensure the validity of such CAPTCHAs, public key installation is\\na mandatory process along with the surety of a secured channel. However, handshaking and\\npublic/private keys pose communication overhead in such schemes.\\n-Audio-visual CAPTCHA: This kind of CAPTCHA scheme is appropriate for illiterate\\npersons. Tariq and Khan [ 15] proposed a novel hybrid CAPTCHA scheme based on images\\nand related sounds. This approach is based on the cognitive abilities of human users. It is a\\nuser-friendly approach; however, databases of images and sounds are required. Similar work\\nexamples are [121] and [122].\\n-Tree-based hand-written CAPTCHA: This CAPTCHA scheme is based on the combination\\nof text and graphics. It exploits the reading abilities of human users. A synthetic hand-written\\ntool is used along with some random transformations to generate a tree structure test [ 123]\\nrandomly. However, an understanding of the tree structure is required.\\n-CAPTCHAs for smart devices: Ubiquity of Internet browsing in smart IoT devices has led\\nto the design of CAPTCHA with special features. Due to constrained resources like memory\\nand energy, it is inevitable to design light-weight CAPTCHAs. These schemes should promote\\ncertain characteristics of touch-screen devices [ 124],[125]. Highlighting CAPTCHA [ 126],\\nmultilingual highlighting CAPTCHA [ 127], CAPTCHA zoo [ 128] and seeSay and hearSay\\nCAPTCHA [129] are few examples of such domain.\\n-CAPTCHAs for Mobile devices: There are some specially designed CAPTCHAs for mobile\\ndevices. They make use of touch screens and the sensors embedded on the device. Such\\nexamples encompass [130], [131], [132], [133], [134], and [135].\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 17}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:19\\nTable 2. Performance analysis of different CAPTCHA Types.\\nTypes CAPTCHA Dictionary-based Database-based Usability Vulnerability Speed and Storage cost\\nOCR Text-Based ✓ ✓ Low High Low\\nOCR 3D-text ✓ ✓ Medium Medium low\\nOCR Hand-written ✓ ✓ Low High Low\\nNON-OCR Image-based × ✓ High Low Medium\\nNON-OCR Audio × ✓ Low Low High\\nNON-OCR Collage × ✓ Medium Medium High\\nNON-OCR Mouse-intervention ✓ ✓ high Medium Medium\\nNON-OCR Video × ✓ High Low Medium\\nNON-OCR Sketcha × ✓ High Medium Medium\\nNON-OCR Public key embedded × ✓ High Medium Low\\nNON-OCR Game × ✓ Low Low High\\nNON-OCR Question-based × ✓ Low Medium Low\\n-Special purpose CAPTCHA schemes: Special purpose CAPTCHA schemes are meant for\\nspecial people, such as visually or deaf and hard of hearing people. The examples of special-\\npurpose CAPTCHAs include [ 122], [17], and [ 136]. Another CAPTCHA scheme specifically\\npresented for children in [137].\\n-CAPTCHA-based passwords: Alajmi et al. [ 41] presented a CAPTCHA-based password\\nauthentication mechanism using AI problem. Another video-based CAPTCHA is proposed\\nin [47]. This scheme is proposed as a graphical password scheme. Muhammad et al. [ 138]\\nalso proposed a graphical password scheme using click-based CAPTCHAs. Khan et al. [ 139]\\nalso proposed a graphical password scheme for security using CAPTCHA. A detailed study\\non CAPTCHAs as graphical passwords is presented in [140].\\n5 CHALLENGES AND OPEN ISSUES IN CAPTCHAS DESIGNS\\nA CAPTCHA is considered good if it is easy for humans to solve and resist potential attacks.\\nHowever, designing such CAPTCHAs is a difficult task. A CAPTCHA is considered usable if it is\\neasy for human users. It is considered strong if it resists computers and with a success rate as low\\nas 0.01% [ 141]. Most of the CAPTCHA breaking techniques are designed for text-based CAPTCHAs,\\nas it is widely used [ 142]. To improve the user-friendliness of CAPTCHA, the presentation of its\\nuser interface needs to be up to par. There is a myriad of qualities that affect the practicality of\\nCAPTCHAs [ 143]. Some of which are; font size, font style, and image size. Problems usually arise\\nwhen humans do not easily recognize the font style and situations that look similar. For instance, a\\nsizeable font is the most suitable in text-based CAPTCHA as it improves human users’ clarity.\\nSimilarly, the size is a fundamental property of image-based CAPTCHA as it also improves\\nusability. Small images are preferable because they depreciate server-processing time, increase\\nthe download process, and inhabits smaller spaces in webpages [ 144]. However, large images are\\nmore precise and more descriptive for human users. They also improve the security prowess of\\nthe CAPTCHA and reduce the probability of speculations [ 145]. Furthermore, the importance of\\nsizeable images is of high importance. A resolution must be made between usability and vigor.\\nAudio-based CAPTCHA is quite different from its other CAPTCHA counterpart, as it does\\nnot depend on presentation. Some studies have shown that audio-based CAPTCHA might be\\ncomplicated for visually impaired users. Bigham and Cavender [ 146] debated that most current\\naudio CAPTCHAs are exasperating for visually impaired users. The latter use screen readers to\\nunderstand CAPTCHA. The rationale behind the debate is that navigation elements cause them\\nto lose concentration and fail to hear the CAPTCHA’s beginning, even as they try to listen and\\nanswer the CAPTCHA questions. The load time can be altered about the user’s network constraint\\nto improve the image’s usability- and motion-based CAPTCHAs [ 147] [148]. Conversion of the\\nanimation quality and dimensions to the grayscale can improve performance.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 18}),\n",
       " Document(page_content='000:20 Noshina et al.\\nThe inference that can be drawn from this is that intellectually disabled users are faced with\\nmore difficulties, followed by visually impaired users [ 149]. The rationale behind this inference is\\nthat intellectually disabled users do not understand CAPTCHAs. For the visually impaired, most\\nCAPTCHAs are understood through a visual canal. Although several steps have been taken to\\nimprove CAPTCHAs’ accessibility for disabled individuals, complete eradication of the problems\\nwill make CAPTCHAs more accessible by computers and robots. The use of substitute methods\\ninstead of CAPTCHAs to avoid spam should be significantly considered. Because after the analysis\\ndone on the subject, substitute methods handle accessibility hurdles better [150].\\nTo enhance CAPTCHA usability and assist human users in identifying aim objects in noisy\\nbackgrounds, zooming. Color filtering tools should be made available. Unavailability of the listed\\ntools can frustrate human users because of background noises in the suggested CAPTCHA, which\\nis the same as some Unicode characters in terms of shape, color, and location [ 31]. The importance\\nof colors in improving CAPTCHA usability cannot be overemphasized as color eases human\\nidentification and confound OCR systems [ 151], [141]. Although colors have their usefulness, one\\nhas to be careful in their application, impairing security and usability. The perplexity associated\\nwith exploiting desirable color patterns and arrangements is one of the adverse effects on human\\nusability. Another adverse effect is the inability to counter-attack.\\nThere is a constant comparison between CAPTCHA and other substitute methods [ 32]. These\\nsubstitute methods, while some may be more efficacious, user friendly, and secure than CAPTCHA.\\nCAPTCHA is still the most common method among users, such as security administrators and\\nbusiness owners. Nevertheless, some substitute methods like spam detection and Askimet plugs\\nare prevalent among users [152]. The rationale behind this penchant is explained below:\\n•Most administrators use third-party solutions [ 153]. They do not code their CAPTCHAs\\nfrom the beginning on the premise of vigor, popularity, cheap execution charge, and low\\nmanagement overhead. Except in crucial and delicate situations, the rationale behind the use\\nof substitute methods is not feasible.\\n•Most administrators are unaware of the new substitute methods, and there is not enough\\ninformation about them [ 32]. Nevertheless, there are third party solutions that provide\\nsubstitutes to users, unlike CAPTCHA. The substitute methods are still upcoming in terms\\nof their diversity and popularity viewpoint.\\n•The fact that most of these substitute methods are not adequately organized and packaged\\nis responsible for most users not using them. The unavailability of these features decreases\\ntheir usability and makes them informal.\\n•Website owners should continue using substitute methods because of CAPTCHAs’ effect\\non accessibility, conversion rate, usability, and user satisfaction. Managers that are aware of\\nthe consequences of using CAPTCHAs and, at the same time, unaware of substitutes have\\nremoved CAPTCHAs from their websites. They now care about their users than they do\\nattackers [32].\\n5.1 Performance analysis\\nSince time immemorial, the text-based CAPTCHA has been the most preferred type of CAPTCHA.\\nAlthough it is unsafe in recent times, text-based security can still be improved using various means\\ndue to its wide usage and complexity. These means may include; use of font styles or noise. Recently,\\nthe most widely used CAPTCHA is image-based. It is advantageous in the sense that it is easier to\\nuse than its text-based counterpart. However, this CAPTCHA might be prone to adversarial attacks;\\nthere is still room for improvement. The most uncommon type of CAPTCHA is the audio/video-\\nbased CAPTCHA. Its atypicality is owed to the premise that it requires higher bandwidth and does\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 19}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:21\\nTable 3. Comparison among different CAPTCHA techniques\\nReference Year Type Technique Characteristics\\nClutter/Noise Deformation Orientation Overlapping User-friendly Scalability\\n[18] 2009 Non-OCR Image ✓ ✓ ✓× Medium Low\\n[15] 2018 Non-OCR Match the sound ×××× High Low\\n[50] 2007 OCR Google, MSN × ✓ ✓ ✓ Medium Low\\n[51] 2004 OCR Gimpy-r and EZ-Gimpy ✓ ✓× ✓ Low Low\\n[58] 2019 OCR 3D DotCHA × ✓ ✓× Low Low\\n[64] 2001 OCR Hand written ✓ ✓× ✓ Low Low\\n[66] 2013 OCR Hollow text ✓ ✓× ✓ Low Low\\n[72] 2007 Non-OCR ASIRRA ✓ ✓ ✓× High Low\\n[73] 2012 Non-OCR Image ✓ ✓ ✓ ✓ High Low\\n[74] 2013 Non-OCR Object recognition ✓×× ✓ High Low\\n[78] 2020 Non-OCR FGSM, I-FGSM ✓ ✓×× High Low\\n[81] 2009 Non-OCR Automated Speech Recognition (ASR) ✓××× Medium Low\\n[85] 2007 Non-OCR Text to Speech (TTS) ✓××× High Medium\\n[86] 2010 Non-OCR Waveform diagrams ✓××× High Medium\\n[17] 2012 Non-OCR Audio ✓ ✓ ✓ ✓ High Medium\\n[88] 2019 Non-OCR Contemporary architecture ✓ ✓ ✓ ✓ High Medium\\n[90] 2013 Non-OCR Hybrid ✓ ✓ ✓× High Medium\\n[91] 2020 Non-OCR Object Segmentation ✓ ✓ ✓ ✓ High Low\\n[92] 2009 Non-OCR DND draggable character × ✓× ✓ High Medium\\n[104] 2007 Non-OCR Question-based × ✓×× High low\\n[108] 2006 Non-OCR Persian and Arabic writing ✓×× ✓ Medium Low\\n[110] 2009 Non-OCR Kerckhoffs’ Principle ✓ ✓ ✓ ✓ Medium Low\\n[111] 2013 Non-OCR Video-based ✓× ✓ ✓ Medium Medium\\n[112] 2010 Non-OCR Drawing CAPTCHA ×× ✓× High Medium\\n[115] 2011 Non-OCR A DevilType, Video Captcha ××× ✓ High Low\\n[116] 2014 Non-OCR Dynamic Cognitive Game (DCG) ×× ✓× High Low\\n[102] 2020 Non-OCR Flash-based ×× ✓× Medium Medium\\n[120] 2008 Non-OCR Hybrid ✓××× High Medium\\n[154] 2008 OCR reCAPTCHA ✓ ✓ ✓ ✓ Low Low\\n[155] 2010 Non-OCR Audio ✓××× High Medium\\n[156] 2006 Non-OCR Mouse Intervention ×× ✓× High Low\\n[157] 2003 Non-OCR Turing test using pessimal print ✓ ✓×× High Low\\nnot save time. Above all, they get broken with ease. Based on our study, the performance analysis\\nof different CAPTCHA schemes is illustrated in Table 2. Similarly, a comparison based on different\\nCAPTCHA characteristics is presented in Table 3.\\nWe observed that the OCR-based CAPTCHAs are mostly dictionary- and database-based. The\\ntrade-off between usability and robustness is the main challenge in the design of a CAPTCHA.\\nText-based CAPTCHAs are the ones that are most frequently used by several websites and web-\\nbased applications. Text-based CAPTCHAs are mainly preferred due to low latency and storage\\ncosts. However, they are more vulnerable than the other CAPTCHA schemes, such as image, audio,\\nor video. Besides, text-based CAPTCHAs are annoying to use due to usability issues. Different\\nsecurity features make it attack-resistant in CAPTCHA designing, such as ’font tricks,’ diversified\\nfont styles, upper or lower case letters, deformation, alteration, distortion, twists, and sizes. Another\\nsuch feature is the ’noise’ [ 50], which is also referred to as clutter. For noise and clutter, different\\nshapes (such as circles, squares, or rectangles), lines (vertical, diagonal, or horizontal), colors, dots\\nmay be used for CAPTCHA security. Similarly, the objects or text may be overlapped to make\\nCAPTCHA resilient against potential segmentation attacks.\\nOn the contrary, non-OCR-based CAPTCHA tests do not require word dictionaries. However,\\na substantially larger database is needed to store images, videos, or sounds. They have different\\ndisadvantages, such as vulnerability, unfriendly, massive image libraries, server loads, downloading\\ndelays, and timely access [ 18]. However, they are less vulnerable than text-based CAPTCHAs.\\nThey are more usable than text-based because they require less noise, clutter, deformation, and\\noverlapping. These features make them more enjoyable and easy to pass.\\nSimilarly, audio-based CAPTCHAs are less supported as non-native listeners/users might face\\nproblems recognizing words/phrases due to accent problems. Moreover, non-native speakers may\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 20}),\n",
       " Document(page_content='000:22 Noshina et al.\\nnot have enough vocabulary. Downloading issues make video-based CAPTCHAs less attractive\\nthan the others. Besides, network delay and the file size may also strain a user’s resources interested\\nin the desired task and not in CAPTCHA solving.\\n5.2 Recommendations for designers\\nAccording to our study, the following are some of the ineluctable factors in designing a robust\\nCAPTCHA.\\n(1) A good CAPTCHA must be resistant against segmentation attacks.\\n(2)Deformation, fragmentation of text/images, lines, and clutter must be added to avoid recog-\\nnition attacks.\\n(3)Distortion, rotations, wrapping of text/images, and random scaling may also make it robust.\\n(4) False boundaries of text/images are also helpful in designing a good CAPTCHA.\\n(5) Apposite selection of multiple backgrounds and foreground colors also enhances security.\\n(6) CAPTCHA must be generated at run-time with enough randomness.\\n(7) Random length and combination of characters must be promoted.\\n(8) Make it sturdy against pixel count attacks, such as by using random wrapping of text.\\n(9) Clever use of words, phrases, and images is required.\\n(10) To avoid database attacks, the use of a large-sized database is mandatory.\\n(11) Feature deformation is helpful in image-based CAPTCHA designing to deter ML-based\\nattacks.\\n(12) A good CAPTCHA must be resilient against random guessing attacks.\\n(13) We can confine the number of attempts and the time taken to solve a CAPTCHA.\\n(14) Question-based CAPTCHA may be based on the logical thinking of humans rather than on\\ncomputations only.\\n(15) A combination of text and images is a good strategy.\\n(16) Make more human interactions through mouse-clicking, screen tapping, drag-n-drop, or\\ndrop-down lists.\\n(17) Machine learning technology is used in both breaking and security enhancements in the\\nCAPTCHA. An example of this technology is the adversarial and neutral style that may give\\nbetter directives for designing CAPTCHA [78].\\n(18) While the need to solve the different challenges might be pressing, some confidential infor-\\nmation is also required [ 158]. Confidential information, such as pass time, pass speed, and\\nthe operation tracks, are needed to differentiate humans from robots.\\n(19) Language comprehension should be paid more attention. As the ability to understand language\\nis a required human skill to improve CAPTCHA in its entirety. Associative power is just\\nanother advanced human skill that can improve CAPTCHA.\\nHowever, if these factors are applied eminently, the usability of the resultant challenge will\\ndecrease. As said earlier that there is a trade-off between robustness and usability. For example,\\nadding more clutter, distortion, or overlapping will result in robust yet less readable and annoying\\nCAPTCHA for human users. Therefore, we need to balance robustness and usability at the same\\ntime in a healthy proportion.\\n6 CAPTCHA BREAKING TECHNIQUES\\nMori and Malik [ 52] gave the idea of CAPTCHA breaking in 2003. They made recognition-based\\nattacks on Gimpy and EZ-Gimpy CAPTCHAs. They attacked many schemes and revealed the\\nweaknesses of different CAPTCHA schemes. This section presents different attacks made on\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 21}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:23\\nFig. 28. The proposed taxonomy of CAPTCHA breaking techniques.\\nvarious CAPTCHA schemes. A taxonomy of different CAPTCHA breaking techniques is shown in\\nFig. 28.\\n6.1 Segmentation Attacks\\nIn breaking a CAPTCHA, segmentation is the most crucial step. A CAPTCHA challenge can only\\nbe well-recognized if the segmentation step is done properly [ 159]. Chellapilla et al. [ 160] claimed\\nthat once CAPTCHA texts are segmented well, recognizing a single character is much better in\\nautomated programs than humans. Pre-processing is done first to remove noise and clutter. Once\\nPre-processing has been done, the process of segmentation is started. A well-segmented image is\\nthen going through the recognition process to break a CAPTCHA scheme [ 67]. A generic view of\\nCAPTCHA breaking steps is given in Fig. 29 followed by some segmentation-based attacks made\\non different CAPTCHA schemes.\\nFig. 29. A generic view of CAPTCHA breaking steps.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 22}),\n",
       " Document(page_content='000:24 Noshina et al.\\n6.1.1 Vertical segmentation. Many visual CAPTCHA schemes are attached by Chellapilla et al. [ 160].\\nAccording to the estimate, the success rate shot from 4.89% to 66.2% in this segmentation. The\\nauthors stated that humans feasibly detected the twisted/distorted word into a complete word on\\naccount of this. Therefore, it is pertinent to mention that they can easily break a segmented text as\\nwell.\\nMicrosoft, Yahoo, and Google CAPTCHA were termed the weakest ones as humans’ capability\\nto break them were relatively higher, says Jeff Yan and Ahmed Salah [ 50]. They took six improperly\\nsequenced letters or numerical digits from services.org CAPTCHA. Even though they were not in\\na sequence, overlapping words could not become possible, making humans rethink every time they\\nclick the expected digit. Hence, segmentation was possible in a vertical position. Each word was\\nthen counted in pixel table after segmentation for recognition, as seen in Fig. 30 and 31.\\nFig. 30. Showing vertical segmentation.\\nFig. 31. Letter A-Z and their pixel count.\\nTable 4 represents the lookup table used in letter-pixel count. The success rate of this approach\\nwas nearly 100%. In contrast, the strategy fails to function in letters with the same number of pixels\\n(highlighted red in Table 4), especially when they overlap. Additionally, suppose the same pixel\\nrefers to more than one character. In that case, it paves the way for ambiguity and malfunctioning\\nof the segmentation algorithm.\\n6.1.2 Snake segmentation. To get rid of the simple segmentation, snake Segmentation [ 50] was\\nused. There is no such rule in Snake Segmentation that it has to be vertical only. As shown in Fig. 32,\\nthe snake can move forward and backwards and up and down to break a picture. Standardization is\\ndone to see the letter, and that happens when the segmentation is done. A success ratio of 96% in\\nthe examples given and 99% on pictures selected randomly was attained. The images with alphabets,\\nwords, or numbers are difficult to break down because they are either joint or overlapping images.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 23}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:25\\nTable 4. Pixel-count lookup table.\\nAlphabet Pixel-count\\nA 183\\nB 217\\nC 159\\nD 192\\nE 163\\nF 133\\nG 190\\nH 186\\nI 121\\nJ 111\\nK 178\\nL 111\\nM 233\\nN 239\\nO 178\\nP 162\\nQ 229\\nR 208\\nS 194\\nT 175\\nU 164\\nV 162\\nW 234\\nX 181\\nY 153\\nZ 193\\nFig. 32. Snake segmentation:(a) Pre-processing,(b) Prior to segmentation(c) After segmentation.\\n6.1.3 Color filling Segmentation. Color filling segmentation was used for pictures that contain only\\ntwo colors, one of them being the background [ 161]. The other color is used for the text; therefore,\\nthe foreground. The foreground letters are dispersed, and to form an image, different colors are\\ncombined, and each pixel’s count in the segment is done. The count done here is then compared\\nwith the count that is in the pixel table. If the count falls short, it is added with its adjoining right\\nand left segment to figure out the correct letter or digit, as shown in Fig. 33.\\nFig. 33. Component identification:(a) Original CAPTCHA(b) Background removal(c) Loop removal.\\nIf there are many arcs placed, then this method is not successful. Megaupload [ 161] made a new\\nsegmentation resistance that was not like Google, Yahoo, or even Microsoft. There are a total of 4\\ndigits and letters that are placed horizontally. Some of the parts have overlapped in them. They\\nare eliminated and are only in two colors, black and white. For color segmentation to be done,\\nthe black and white parts are taken out one after another. They are added to recognize the white\\ncomponents, and any clutter or background loops are cut off. They are added together to make\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 24}),\n",
       " Document(page_content='000:26 Noshina et al.\\nFig. 34. Final recognized characters.\\na letter in the end. In 100 sample tests, the success ratio is 82% with sufficient attack speed; 400\\ndifferent samples had a success ratio of 78.25%. However, serious problems can be caused if two or\\nmore of the characters are joined to the black part, as shown in Fig. 34.\\nIf the loop is not recognized accurately, a problem can occur. Another similar attack is launched on\\nimage-based CAPTCHAs, IMAGINATION, in [ 162]. They used a color-edge and line-segmentation\\ndetection mechanism. One hundred and nine (109) images of the said CAPTCHA scheme were\\nbrought together online, and with a success ratio of 74.31%, they broke 81 CAPTCHA images.\\n6.1.4 Projection-based segmentation. To break the CAPTCHA scheme, there are two basic methods;\\nidentification and segmentation [ 163]. The procedure of identification acknowledges a character\\nwhen it has been segmented well. Letters and clutter were identified separately through label\\nsegmentation, and Chellapilla [ 164] also used it. The segmentation method fails of the difference is\\nnot much, and the characters tend to break to eliminate noise. As shown in Fig. 35, projection-based\\nsegmentation was used by Huang et al. [ 163] for Yahoo and MSN CAPTCHAs. The technique used\\nby them had a rate of success of 9% more than the Chellapilla. As it helps to get rid of the clutter\\nand noise, that is the advantage it has over Chellapilla. To analyze the CAPTCHAs, this technique\\nhelps to give a new dimension.\\nFig. 35. (a) Test image (b) Projection-based image.\\n6.1.5 DeCAPTCHA. Bursztien and Bethard [ 81] attacked eBay audio CAPTCHA. They represented\\na proposal, ’DeCAPTCHA’, in order to break the sound-based CAPTCHA schemes. ’CAPTCHA\\nchorus’ is made by the scraper to make such an attack. To break Sound CAPTCHAs, we can\\nuse Sphinx [ 165], which is a state-of-the-art sound recognizer. A graph is made when the audio\\nis changed to features to decode the words and letters that are said. For this purpose, auditory\\nand language modules are needed. The DeCAPTCHA broke a total of 75% of the sound-based\\nCAPTCHAs, and the downloads were limited for this reason.\\n6.1.6 K-Means layered segmentation. As shown in Fig. 36, there are transactions conducted in\\nthe e-banking on the CAPTCHA verification bases to avoid attacks by the bot. They help prevent\\nunauthorized access and keep it safe from attacks by a Man-in-the-Middle (MitM). The pattern\\ndetected is processed by a tool, namely K- mean layered segmentation. There are three layers of e-\\nbanking CAPTCHAs, the first one having grids that are placed erratically. User birthday entrenched\\nis the second layer, with each letter and digits having font style, location, and random alternation.\\nThe final uppermost layer has a transaction date on it. There are several steps to carry the attack\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 25}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:27\\nout. To better the e-banking CAPTCHA, there are good lines provided. The rate of success is around\\n100% for breaking e-banking CAPTCHA. Li and Khayam [ 166] suggested not to use the e-banking\\nCAPTCHA and use hardware security accomplishment instead.\\nFig. 36. Segmentation results of a Ge-Captcha image.\\n6.1.7 Filter-based segmentation. A low cost yet powerful attack based on Log-Gabor filters is\\nproposed in [53] to break various designed text-based CAPTCHAs. The attack shows a 5% to 77%\\nsuccess rate with less than 5 seconds on average to break a single instance of text CAPTCHA. They\\nalso compared Log-Gabor filters accuracy with other filter-based segmentation schemes, such as\\n2D Gabor filters and steerable filters. The results show that the Log-Gabor filter segmentation\\noutperformed on character extraction than the two, as shown in Fig. 37.\\nFig. 37. character component extraction using Gabor filters.\\n6.2 ML- and DL-based attacks on CAPTCHAs\\nAutomated processes can also break CAPTCHAs with ML and speech recognition algorithms.\\nGolle [167] showed that ML-based attacks have a 10.3% success rate on Asirra. Similarly, in [162],\\nan ML-based attack is made on image-based CAPTCHAs with a 40% success rate. Saroha et al. [ 168]\\nused a backpropagation-based mechanism for CAPTCHA recognition. The following are some\\nML-based techniques used in CAPTCHA breaking.\\n6.2.1 Convolutional Neural Network (CNN). CNN is used for analyzing visual imagery, and they\\nare good in areas like image classification [ 169]. The other variants of CNN, such as Regions with\\nCNN features (RCNN) and Fast-RCNN, Faster RCNN, YOLO, and SSD, are integrated with improved\\nsecurity features and object detection accuracy [ 170], [171], [172], and [ 173]. CNN is equipped with\\na better mechanism with enhanced accuracy and time complexity. However, CNN’s establishment\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 26}),\n",
       " Document(page_content='000:28 Noshina et al.\\nrequires much effort, including pre-trained staff members and much homework [ 174]. Furthermore,\\nit requires a large quantity of high-quality data along with a dependable neural network. Hence, it\\nrequires a high initial cost [ 159]. A CNN-based Chinese text-based CAPTCHA breaking mechanism\\nis proposed in [ 175]. Similarly, Stephen and Lu [ 176] assessed cyber security vulnerabilities by\\nbreaking CAPTCHAs using CNN. A semi-supervised DL-based (CNN) approach is used in [ 177]\\nfor breaking common CAPTCHA schemes.\\nFig. 38. CNN network structure.\\n[178] proposed non-redundant merging with an accurate filling scheme for cracking the hollow\\nCAPTCHA. In solid characters, they applied the nearest-minimum neighbor merging algorithm for\\ngaining the correct individual characters. They used CNN to obtain the final recognition results\\nwith a success rate of 97.50% for individual characters and 91.00% for single images. A depiction\\nis shown in Fig. 38 [ 170] discussed three different proof-of-concept attacks for selection-based\\nCAPTCHAs, slide-based CAPTCHAs, and click-based CAPTCHAs. They break the CAPTCHA of\\n10 real-world security systems. They also discussed this method’s working efficiency with previous\\nmethods, i.e., image recognition service and humans involved in the CAPTCHA solving process.\\nThe success rate of the scheme is 85.72%-99.65%.\\nA Deep Convolutional Neural Network (DCNN) was presented to break such CAPTCHAs based\\non a confusion class. However, it has low recognition accuracy. Therefore, the selective-learning\\nconfusion class was introduced to overcome this problem for text-based CAPTCHAs in [ 179].\\nThe process involves a two-stage DCNN framework based on the confusion relation matrix. The\\npartitioning algorithm improved 1.4%-39.4% for confusing characters for confusion class DCNN\\nand the validation and training algorithm. Another DCNN-based attack is made on image-based\\nCAPTCHAs in [ 180]. They took 25,000 test images, and the accuracy rate is as high as 95.2%.\\nSimilarly, Zhang et al. [ 181] propounded Captchanet as a classification mechanism for Chinese\\ncharacter-based CAPTCHAs with better accuracy than other DL-based mechanisms. Another\\nCAPTCHA recognition scheme is presented by Wand and Shi [ 182] based on CNN with 99%, 97.84%,\\nand 98.5%, recognition rate.\\n6.2.2 Deep learning. Deep learning is considered the most dominating method among different\\nexisting techniques from the last few years. Due to this method, the existing techniques have devel-\\noped significantly better recognition than humans. Deep neural networks usually are integrated\\nwith all the levels of features and end-to-end based classifiers involving the multiple layer fashion\\nenriched with the numbers of depths [ 183]. They have the degradation issue when these start to\\nconverge, which increases with the increasing depth and results in reduced accuracy [ 184]. This\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 27}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:29\\ntechnology is employed in different recognition fields, such as image, text, and audio recogni-\\ntion. These techniques, such as CNN, RNN, LSTM-RNN, are some to mention, which are used in\\nCAPTCHA recognition [67].\\nAs discussed earlier, the CNN approach recognises characters’ images without extracting the\\nfeatures and is strong in displace, deformation, and scaling. The research [ 185] shows that the\\nrecognition of CAPTCHA with a distributed deep convolutional neural network has an accuracy of\\n99.8%. However, it cannot be combined with context information recognition due to time constraints.\\nHence, feedback and time parameters based RNN was proposed for handling time series data.\\nHowever, despite that, this scheme has a dispersing gradient issue. Therefore, the LSTM approach\\nwas proposed [ 186], using the 2D LSTM-RNN for recognizing CCT CAPTCHAs with the accuracy\\nof 55.2%. This approach was successful in obtaining the relevant information on the horizontal\\nas well as the vertical axis. This paper proposes the generic, simple, and fast attack approach for\\ndecoding text CAPTCHA with a superposition challenge. Similarly, Tang et al. [ 187] proposed a\\ngeneric, simple, yet fast approach for decoding CAPTCHA schemes with the superposition. The\\ndeep learning-based breaking of roman-text-based character CAPTCHA with the success rate of\\n10.1%-90.0%. The scheme also attacked three Chinese CAPTCHAs with success rates of 93.0%,\\n32.2% and 28.6%, respectively. Sivakorn et al. [ 188] designed a novel low-cost attack that controls\\nFig. 39. LeNet-5 feed-forward architecture.\\nthe semantic annotation of images through deep learning technology on image-reCAPTCHA and\\nFacebook image CAPTCHA schemes. The accuracy rate of the said scheme is 70.78% for image\\nreCAPTCHA and 83.50% for Facebook image CAPTCHA.\\n6.2.3 Support Vector Machine (SVM). SVM is also considered a proficient classification technique.\\nIt is based upon Statistical Learning Theory with many advantages, such as robustness, accuracy,\\nand effectiveness, even with few training samples. They are non-parametric binary classifiers by\\nnature. It works by separating classes through a hyper-plane. The kernel function uses a key, which\\ndecodes the original features and converts them into high-dimensional space in a nonlinear way,\\nenhancing the separability for data [ 67]. They are widely applied in machine vision fields like\\ncharacter, hand-writing digitization, text recognition, and even satellite image classification [ 189].\\nStarostenko et al. [ 190] presented an innovative approach for solving the automatic segmentation\\nand recognizing reCAPTCHAs and other text-based CAPTCHAs using an SVM-based classifier.\\nDifferent font sizes having different waving patterns and rotation in this approach collapse in\\nrandom over-lapping characters. The suggested segmentation process is founded on three-color\\nbar character encoding, which separates the letter in reCAPTCHA. The average segmentation rate\\nwas up to 82%, while the SVM classifier success rate was almost 94%. However, this technique\\nfails in decoding the reCAPTCHAs of 2012. Another such technique is proposed in [ 167], broke\\nimage-based CAPTCHAs using SVM with an 82.7% accuracy rate.\\n6.2.4 Fuzzy logic. Out of other techniques in clustering, the most commonly used algorithms is\\nthe Fuzzy C-Means (FCM). Fuzzy logic is widely used for image segmentation. The mechanism is a\\nwell-known clustering approach that uses numerical data (k-means method) or large datasets, i.e., a\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 28}),\n",
       " Document(page_content='000:30 Noshina et al.\\nFig. 40. The GUI visualization of character segmentation and SVM-based recognition used in [190].\\ntiered method for solving dissimilarity matrices [ 191]. It works by partitioning the finite collection\\ninto sets of cfuzzy clusters. It results in the formation of clusters involving every element to a\\ncertain degree. These elements can also belong to the different clusters at the same time, i.e., soft\\nclustering. A fuzzy logic-based mechanism is propounded in [ 192] by Fonseca et al. for recognizing\\ngeometrical shapes interactively.\\nTheir algorithm can easily recognize elementary geometrical shapes like triangles, rectangles,\\ncircles, and ellipses. It observes and collects the geometrical features of different shapes from the\\ndatabase and combines them to recognize the final geometrical figure. They used the perimeter\\nand area to recognize features that separate all the geometrical figures, as given by Grahm’s\\nAlgorithm [ 193]. After this, each fuzzy set belonging to each feature was used for the recognition\\nof shapes. Sasi et al. [ 194] studied the application of fuzzy set theory for the classification of hand-\\nwritten characters sets. Initially, all the hand-written characters were classified into 4x4 matrix\\ncells. They were analyzed and stored in the database under different categories. Another edge\\ncorner-based segmentation–recognition mechanism is proposed by Nachar et al. [ 195] using fuzzy\\nlogic for breaking different types of CAPTCHA schemes. The success rate for eBay, Wikipedia,\\nReCAPTCHA, and Yahoo was 68.2%, 76.7%, 62.5%, and 57.3%, respectively.\\nFig. 41. Edge corner-based fuzzy logic segmentation and recognition.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 29}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:31\\nFig. 42. A GAN-based Pre-processing model proposed in [54].\\n6.2.5 Artificial neural networks (ANN). For image recognition, different neural network approaches\\nhave been proposed. All interconnected units, called artificial neurons, are trained to solve com-\\nplex problems. Each neural network consists of hundreds of layers, which are the same as the\\nhuman brain. However, neural networks require intensive training with thousands of samples\\nalong. Moreover, the quality of training data and feature extraction also play an important role in\\nfinal recognition [ 67]. Simard et al. [ 196] came forward with their application for visual documen-\\ntation analysis. Another ANN-based mechanism is proposed by Koerich et al. [ 197] using discrete\\nHidden Markov Models (HMM) for unconstrained hand-written words’ recognition and verification.\\nFurthermore, Kaur et al. [ 198] showed that an ANN system could also be used to recognize the\\ncharacter. Barve et al. [ 199] showed that an optical character recognition system designed with\\nANNs could have high noise tolerance. In [ 186], a BPNN employed a cross entropy method using\\nRecurrent Neural Network (RNN) to calculate the network’s performance. The overall precision for\\nthe CCT CAPTCHAs of Taobao is 51.3%. It is 27.1% for MSN and 53.2% for the eBay. However, the\\nmain problem is the extraction character feature of high quality, limiting the final results.\\n6.2.6 Generative Adversarial Networks (GAN). A GAN uses a generative network for generating\\nmock examples and a discriminate network for distinguishing the produced examples from the actual\\nscenarios. For this purpose, back-propagation is used to train both networks; after some training\\niterations, the generators give better mock samples. In contrast, the discriminator becomes better\\nusing flagging synthetic data [ 54]. GANs showed the extraordinary results in image [ 200][201]\\nand natural language [ 202][203] processing tasks. However, due to the technique’s freshness,\\nno literature work is available where GANs were used for solving the text-based CAPTCHAs.\\nTherefore,a GAN-based bot is proposed in [ 54] for solving text-based CAPTCHAs. The bot uses\\ntraining data and can solve a wide range of text-based CAPTCHA schemes. The deviation from the\\npast ML-based attacks requires few newly created CAPTCHAs for building the solver. It is achieved\\nby learning the synthesizer and then generating training data for building a solver base. It them\\nrefines the solver through transfer learning on real CAPTCHAs data sets. The main advantage of\\nthis approach is that it requires very little human intervention for learning.\\n6.2.7 K-nearest neighbours (KNN). KNN is designed on the category having the nearest ksamples\\nfor determining the category of a test sample. KNN is the most commonly used recognition classifier\\nfor breaking text-based CAPTCHA systems. However, the accuracy of KNN classification depends\\non the size of samples and the value of k. In [ 53], several approaches like SVM, BPNN, template\\nmatching, CNN, and KNN were tested. The results showed that KNN achieved the highest success\\nrates for most schemes, whereas CNN showed better results in the shortest time.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 30}),\n",
       " Document(page_content='000:32 Noshina et al.\\nFig. 43. Identifying 24 minipatches in the image.\\nFig. 44. Gimpy-r challenge with background removal.\\n6.3 Distortion estimation technique\\nDistortion-estimation techniques break EZ-Gimpy and Gimpy-r CAPTCHAs. A 99% accuracy on\\nEz-Gimpy and 78% on Gimpy-r CAPTCHAs is projected by Gabial Moy et al. [ 51]. They used\\na dictionary of 561-word in breaking Ez-gimpy and a four-letter word dictionary for Gimpy-r\\nCAPTCHAs. The correlation is used in matching words by cores and minipatches identification, as\\nshown in Fig. 43 and 44. The correlation mechanism gave high success and accuracy rates; however,\\nit failed in identifying high distorted images. Also, the dictionary used in breaking was small, which\\nmade execution ineffective. However, on the increased size of slicing, the execution time increased,\\nas well.\\n6.4 Dictionary attacks\\nIn networks, a user is likely to encounter a Denial of Services (DoS) attack [ 204]. While in an\\nallotted time restriction, if the amount of guesses is incorrectly made, the account becomes locked.\\nThe issue is encountered by legitimate users who end up facing service poverty. To get the better\\nof these kinds of issues, EZ-Gimpy and Gimpy CAPTCHAs had been initiated. Mori and Malik [ 52]\\nstruck the mentioned variations of CAPTCHAs, turning it uncertain by virtual brute force strikes.\\nThe procedure of this kind of attack is displayed in Fig. 45 and 46.\\nText-based CAPTCHAs are where brute force attacks are formed, especially those containing a\\nfile. If not, then a database is linked alongside them. Yan and Salah [ 50] used gullible arrangement\\nidentification techniques to shatter a category of visual CAPTCHA. The highlighted issue of evident\\nsegmentation and pixel counts was conquered with the use of brute force strikes. A word is primarily\\nsent through connection and, after that, from recognition. However, the scheme malfunctions if\\ndisconnected or linked letters are greater than 3 in numbers or all displayed or entered letters are\\njoined. Brute force strikes are doable for words that are entered in the English language. However,\\nunsystematic character/inclusion of digit CAPTCHA cannot be fractured by such variations of\\nstrikes.\\n6.5 Reverse engineering method\\nHindle and Michael. [ 205] came up with the suggestion of reverse engineering for breaking a\\nparticular CAPTCHA scheme, as shown in Fig. 47. They compared CAPTCHAs’ weakness after\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 31}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:33\\nFig. 45. A basic attack: a failing example where segmentation is not possible between ’k’ and ’s’.\\nFig. 46. A basic attack with dictionary enhancement.\\nFig. 47. Model of computer CAPTCHA solving.\\nbreaking them to highlight the way to make them more robust. However, it uses a bit map illustration\\nsolely for CAPTCHAs based on text.\\nThe accuracy level of the technique used for PHPBB CAPTCHA is 99%. For Rogers CAPTCHAs,\\nit is 95%, for Piratebay is 61% and for Watercap CAPTCHA is 27%. This perspective has provided\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 32}),\n",
       " Document(page_content='000:34 Noshina et al.\\nadequate proposals for building CAPTCHAs more applaudable. However, it is unable to take in the\\nuse of sound and visual-based CAPTCHAs.\\n7 CHALLENGES AND OPEN ISSUES IN CAPTCHA BREAKING TECHNIQUES\\nAs mentioned before, there are different types of CAPTCHAs, such as text, image, audio, or video.\\nThey provide security against malevolent bot attacks. Unfortunately, they have the same fate and\\nprone to breaking attacks [ 206]. Their security and usability, at the same time, is a challenging\\ntask. The current study on CAPTCHA reveals that although much work has been done on their\\nsecurity, however, there are still design vulnerabilities that make them insecure [ 25], [187], [207].\\nPreviously (in this paper), it is observed that several attacks are made on well-known CAPTCHA\\nschemes, such as breaking of reCAPTCHA used extensively by Google. That is because there is no\\nstandardized mechanisms and practice for designing robust CAPTCHAs. Therefore, by exploiting\\ntheir vulnerabilities, the hackers manage to break CAPTCHAs readily to harm the target source.\\nAnother important reason behind breaking CAPTCHAs is to find their design vulnerabilities\\nto bring security improvements in their design. There are different steps that are involved in\\nCAPTCHA breaking, such as pre-processing [ 208], image processing [ 209], pattern matching [ 210],\\nML [ 211], are just to name a few. The pattern matching-based attacking technique was widely used\\nin the beginning. The downside of this attack is that it requires manual instructions to extract\\nfeatures for different CAPTCHA types. On the contrary, segmentation attacks are the most typical\\ntype of attack. Conversely, this method is not suitable for real-time attacks because it requires a\\nprolonged duration, affecting the breaking speed. There are other end-to-end attacking models,\\nwhich use ML-based models, for example [ 212], [213], and [ 174]. However, they require more\\nhardware and computational resources. For instance, a deep learning approach to recognize a\\nCAPTCHA in its entirety requires high hardware requirements. Under the light of our findings,\\nTable 5. A summary of different CAPTCHA breaking techniques\\nAttack type Algorithm Summary\\nRef. Year Accuracy Samples CAPTCHA\\nMachine learning Distortion estimation [51] 2004 99% 561 Text\\nK-nearest neighbors [53] 2016 77.2% – Text\\nGAN [54] 2018 87.4-90% 500 Text\\nCNN [67] 2018 91% 200 Text\\nCNN [159] 2018 99.75% – Text\\nML [162] 2010 40% 800 Image\\nSVM [167] 2008 82.7% 13K Image\\nML [180] 2018 95.2% 25K Image\\nDCNN [185] 2014 99.8% 100k Text\\nRNN [186] 2011 27-53.2% – Text\\nDL [188] 2016 70.78% 700 Image\\nDL [188] 2016 83.50% 700 Image\\nFuzzy logic [195] 2015 57.3-76.7% – Text\\nSegmentation Snake [50] 2007 94% 100 Text\\nVertical [50] 2007 99% 100 Text\\nDivide and Conquer [66] 2013 83% 1k Text\\nColour filling [161] 2010 78% 400 Text\\nColor-edge & line segmentation [162] 2010 74.31% 109 Image\\nProjection [163] 2008 75% – Text\\nK-Means [166] 2010 100% 100 Text\\nDictionary OCR [50] 2007 99% 100 Text\\nTM/OCR [159] 2018 98.98% – Text\\nDistortion Estimation Reverse engineering [205] 2008 93% 100 Text\\nSoftware-based Decaptcha [81] 2011 75% 26k Audio\\nThe following points must be considered in designing attacks for breaking a CAPTCHA scheme:\\n(1)The CAPTCHAs, especially text-based, are mostly broken using segmentation attacks. There-\\nfore, segmentation-strategies must be revisited to tranche the overlapped text/objects.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 33}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:35\\n(2)A larger size of dictionary/database must be kept updated to launch dictionary attacks.\\nBesides, pixel statistics should also be revised from time to time.\\n(3)The end-to-end attack is one of the most foremost directives for CAPTCHA breaking [ 174].\\nThese attacks are mostly Dl-based, which pose particular challenges in terms of required\\nresources. Thus, there needs to have a lightweight and more convenient DL-based CAPTCHA-\\nbreaking approach.\\n(4)There is a problem associated with ML techniques, which requires a significant number of\\nconstrued datasets. This problem cannot be disregarded, so much so that a less dependent\\nmodel on the training dataset is required.\\n(5)An exclusive trained system is required to break different CAPTCHA. A more non-specific\\nnetwork that can be moved to multiple means is needed because dataset labeling is expensive.\\n(6)An ML-based algorithm, such as DL, is a threat to CAPTCHA security. Hence, a new\\nCAPTCHA defense system is needed to be equipped enough to counter it [ 187]. Multi-\\nlayer feature representations and abstractions from various kinds of data are the most critical\\npurpose of ML. With deep learning, a convolution neural network was applied to image\\nclassification. A myriad of other tasks since 1989, such as [ 214], [215], [216], [217], [218],\\nand [ 219] have been proposed. AlexNet, in recent times, has enhanced the architecture of\\nCNN and notably to improve the classification effect [ 25]. It has also become the customary\\ntrainers for CNN on GPUs [26].\\n(7)There is a limit in ML technology when involved with AI image processing, such as; sym-\\nmetry [ 220] and adversarial examples [ 221] and [ 222]. According to Osadchy et al. [ 223],\\nCAPTCHA designed using concerning deep learning limitations is a viable future explo-\\nration [221].\\n(8)Web access and software generation are the two ways in which researchers get the CAPTCHA\\nsamples. The importance of standard test databases as a requirement for breaking in database-\\nbased CAPTCHAs, such as traditional test databases, is necessary for an improved text-based\\nCAPTCHA.\\n(9)A database is required to provide dependable testing and training data for analytical work.\\nTherefore, to gather, categorize, arrange, and initiate a CAPTCHA database is of high impor-\\ntance.\\n(10) There is a myriad of feature changes in a CAPTCHA. Presently, the efficacious identification\\nof CAPTCHAs by a classifier can only be made when training sets and set types belong to\\nthe same class. Therefore, it is quite onerous and necessary to design a standard classifier to\\nidentify different CAPTCHA types.\\n(11) The high success rate that has been achieved by Text-based CAPTCHA breaking is astounding.\\nSadly, Crowding Characters Together (CCT) strings have been widely used in the text-based\\nCAPTCHA, causing a snag in the results [ 77]. This drawback is due to the problem associated\\nwith the segmentation-free CAPTCHA identification; a situation that requires immediate\\nattention. This problem may be solved using deep learning because of its new ideas and\\ntechniques.\\n(12) Machine learning has been found to deliver quality results than other conventional tech-\\nniques [ 224]. For instance, CNN and its improved methods, Deep Belief Networks (DBN) [ 225],\\nRNN [ 226], and Deep Reinforcement Learning (DRL) [ 227], are the most applied techniques.\\nHowever, they still are not frequented in CAPTCHA identification. Although careful analysis,\\nthe application of fusion and correlation between the different deep learning types is not\\nthorough. There is still a need for more effective and efficient learning models to enable ease\\nin CAPTCHA identification.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 34}),\n",
       " Document(page_content='000:36 Noshina et al.\\nFig. 48. Accuracy comparison of different ML-based attacks.\\nFig. 49. Accuracy comparison of different segmentation attacks.\\nFig. 50. Accuracy comparison of miscellaneous attacks.\\n(13) There has been an increase in identification results’ dependability due to better breaking\\nCAPTCHA techniques. Therefore, there is a need to certify the correct rejection, dismissal,\\nand improve the accuracy rate of recognition. Rejection as a concept is not well-known in\\nthe CAPTCHA recognition field. It is, however, quite clear that it can be developed.\\n(14) In the extraction of features automatically, using ML, characters with similar characteristics\\nare handily muddled. Practically, the accuracy of feature extraction and training methods\\ncan be improved by various ML-based techniques, such as DL and its variants [26].\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 35}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:37\\n7.1 Performance analysis of CAPTCHA breaking techniques\\nIn keeping with our study, Table 5 presents a summary of the comparison among different state-\\nof-the-art CAPTCHA breaking mechanisms. As said earlier, ML-based attacks are widely used in\\nCAPTCHA breaking, out of which DL variants are the most prominent. As depicted in Fig. 48,\\nDCNN [ 185] outperformed other ML techniques with a 99.8 percent accuracy rate. Similarly, we\\nmake a comparison of segmentation-based attacks, shown in Fig. 49. Among all, the K-Means-\\nbased [ 166] segmentation attack outperformed others with accuracy as high as 100 percent. And\\nthen comes the vertical segmentation attack [ 50] with a 99 percent accuracy rate. However, both\\nthe breaking techniques are old and were used a decade before. Thus, they might not work equally\\nwell on today’s advanced CAPTCHA schemes. We also compared other breaking techniques, whose\\ndepiction is shown in Fig. 50.\\n8 CONCLUSION\\nDeciding whether the user is a human or a malicious bot program is challenging for a web service\\nprovider. CAPTCHA is a security mechanism used against automated malicious bot programs.\\nThere are different types of CAPTCHA based on their formation and structure for distinguishing\\nhumans and machines apart. This survey provided an in-depth analysis of various CAPTCHA\\nschemes categorized as OCR and non-OCR CAPTCHA schemes. We analyzed the usability and the\\ndesign loopholes of each CAPTCHA type. The most crucial issue in CAPTCHA designing is the\\ndeformation and noise, compromising its usability and making it annoying for a human user. This\\nstudy spotlit the design vulnerabilities and suggestions to the designers for making CAPTCHA\\nschemes more user-friendly yet attack-resistant. Besides, it also highlighted the challenges and\\nopen issues in CAPTCHA designing.\\nHowever, CAPTCHA security is still a question. They are subject to attacks. There are different\\nbraking techniques, such as segmentation, ML-, and DL-based attacks. Among others, it is noted\\nthat ML-based, especially DL-based breaking schemes, are more dominantly practiced. This survey\\nshowed the vulnerabilities of different CAPTCHAs schemes based on the state-of-the-art CAPTCHA\\nbreaking schemes. It also provided an in-depth analysis of these breaking schemes.\\nMoreover, it highlighted challenges and open issues in breaking the various CAPTCHA schemes.\\nIt also provided a discussion on CAPTCHA breaking techniques that how better breaking techniques\\nmight be designed. The study would help in the usable and attack-resistant CAPTCHA designing.\\nIn the future, we aim to design a robust and user-friendly image-based CAPTCHA that is also\\nscalable.\\nREFERENCES\\n[1]Noshina Tariq, Muhammad Asim, Farrukh Aslam Khan, Thar Baker, Umair Khalid, and Abdelouahid Derhab. A\\nblockchain-based multi-mobile code-driven trust mechanism for detecting internal attacks in internet of things.\\nSensors , 21(1):23, 2021.\\n[2]Abdelouahid Derhab, Rahaf Alawwad, Khawlah Dehwah, Noshina Tariq, Farrukh Aslam Khan, and Jalal Al-Muhtadi.\\nTweet-based bot detection using big data analytics. IEEE Access , 9:65988–66005, 2021.\\n[3]Nitirat Tanthavech and Apichaya Nimkoompai. Captcha: Impact of website security on user experience. In Proceedings\\nof the 2019 4th International Conference on Intelligent Information Technology , pages 37–41, 2019.\\n[4]Yang-Wai Chow, Willy Susilo, and Pairat Thorncharoensri. Captcha design and security issues. In Advances in Cyber\\nSecurity: Principles, Techniques, and Applications , pages 69–92. Springer, 2019.\\n[5]Temur ul Hassan, Muhammad Asim, Thar Baker, Jawad Hassan, and Noshina Tariq. Ctrust-rpl: A control layer-based\\ntrust mechanism for supporting secure routing in routing protocol for low power and lossy networks-based internet\\nof things applications. Transactions on Emerging Telecommunications Technologies , 32(3):e4224, 2021.\\n[6]Afsheen Ahmed, Rabia Latif, Seemab Latif, Haider Abbas, and Farrukh Aslam Khan. Malicious insiders attack in\\niot based multi-cloud e-healthcare environment: a systematic literature review. Multimedia Tools and Applications ,\\n77(17):21947–21965, 2018.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 36}),\n",
       " Document(page_content='000:38 Noshina et al.\\n[7]Muhammad Imran, Muhammad Hanif Durad, Farrukh Aslam Khan, and Abdelouahid Derhab. Toward an optimal\\nsolution against denial of service attacks in software defined networks. Future Generation Computer Systems , 92:444–\\n453, 2019.\\n[8]Zhiyou Ouyang, Xu Zhai, Jinran Wu, Jian Yang, Dong Yue, Chunxia Dou, and Tengfei Zhang. A cloud endpoint\\ncoordinating captcha based on multi-view stacking ensemble. Computers & Security , 103:102178, 2021.\\n[9] Gil Gonen, Ronen Haber, and Arie Haenel. Secure captcha test, March 1 2018. US Patent App. 15/249,493.\\n[10] Ping Wang, Haichang Gao, Xiaoyan Guo, Chenxuan Xiao, Fuqi Qi, and Zheng Yan. An experimental investigation of\\ntext-based captcha attacks and their robustness. ACM Computing Surveys , 55(9):1–38, 2023.\\n[11] Jie Zhang, Min-Yen Tsai, Kotcharat Kitchat, Min-Te Sun, Kazuya Sakai, Wei-Shinn Ku, Thattapon Surasak, and Tipajin\\nThaipisutikul. A secure annuli captcha system. Computers & Security , 125:103025, 2023.\\n[12] Ping Wang, Haichang Gao, Chenxuan Xiao, Xiaoyan Guo, Yipeng Gao, and Yang Zi. Extended research on the security\\nof visual reasoning captcha. IEEE Transactions on Dependable and Secure Computing , 2023.\\n[13] Noshina Tariq, Muhammad Asim, and Farrukh Aslam Khan. Securing scada-based critical infrastructures: Challenges\\nand open issues. Procedia Computer Science , 155:612–617, 2019.\\n[14] Mohinder Kumar and Manish Kumar Jindal. Benchmarks for designing a secure devanagari captcha. SN Computer\\nScience , 2(1):1–16, 2021.\\n[15] Noshina Tariq and Farrukh Aslam Khan. Match-the-sound captcha. In Information Technology-New Generations ,\\npages 803–808. Springer, 2018.\\n[16] L. Von Ahn, M. Blum, N. Hopper, and J. Langford. Captcha: Using hard ai problems for security. Advances in\\nCryptology, EUROCRYPT 2003 , pages 646–646, 2003.\\n[17] Jonathan Lazar, Jinjuan Feng, Tim Brooks, Genna Melamed, Brian Wentz, Jon Holman, Abiodun Olalere, and Nnanna\\nEkedebe. The soundsright captcha: an improved approach to audio human interaction proofs for blind users. In\\nProceedings of the SIGCHI conference on human factors in computing systems , pages 2267–2276. ACM, 2012.\\n[18] MT Banday and NA Shah. Image flip captcha. ISC International Journal of Information Security (ISeCure) , 1(2):105–123,\\n2009.\\n[19] Suliman A Alsuhibany. A survey on adversarial perturbations and attacks on captchas. Applied Sciences , 13(7):4602,\\n2023.\\n[20] Mohinder Kumar, MK Jindal, and Munish Kumar. A systematic survey on captcha recognition: types, creation and\\nbreaking techniques. Archives of Computational Methods in Engineering , 29(2):1107–1136, 2022.\\n[21] Menna Magdy, Medhat A Tawfeek, and Hamdy M Mousa. A comprehensive study for different types of captcha\\nmethods and various attacks. 2021.\\n[22] Mohinder Kumar, MK Jindal, and Munish Kumar. A systematic survey on captcha recognition: Types, creation and\\nbreaking techniques. Archives of Computational Methods in Engineering , pages 1–30, 2021.\\n[23] Mohit Srivastava, Shreya Sakshi, Sanghamitra Dutta, and Chitrapriya Ningthoujam. Survey on captcha recognition\\nusing deep learning. In Soft Computing Techniques and Applications , pages 273–282. Springer, 2021.\\n[24] Gannavarapu Ananth Kumar and Garg Rishav. Captcha techniques of secure web authentication: A survey. In\\nCommunication Software and Networks , pages 97–117. Springer, 2021.\\n[25] Yang Zhang, Haichang Gao, Ge Pei, Sainan Luo, Guoqin Chang, and Nuo Cheng. A survey of research on captcha\\ndesigning and breaking techniques. In 2019 18th IEEE International Conference On Trust, Security And Privacy In\\nComputing And Communications/13th IEEE International Conference On Big Data Science And Engineering (Trust-\\nCom/BigDataSE) , pages 75–84. IEEE, 2019.\\n[26] Xin Xu, Lei Liu, and Bo Li. A survey of captcha technologies to distinguish between human and computer. Neuro-\\ncomputing , 408:292–307, 2020.\\n[27] Antreas Dionysiou and Elias Athanasopoulos. Sok: Machine vs. machine–a systematic classification of automated\\nmachine learning-based captcha solvers. Computers & Security , page 101947, 2020.\\n[28] N Divyashree and ST Kumar. A survey on captcha categories. Int. J. Eng. Comput. Sci , 5(5):16458–16462, 2016.\\n[29] Meriem Guerar, Alessio Merlo, and Mauro Migliardi. Completely automated public physical test to tell computers\\nand humans apart: A usability study on mobile devices. Future Generation Computer Systems , 82:617–630, 2018.\\n[30] Mecheal Greene. Large scale captcha survey . PhD thesis, University of Delaware, 2018.\\n[31] Narges Roshanbin and James Miller. A survey and analysis of current captcha approaches. J. Web Eng. , 12(1&2):1–40,\\n2013.\\n[32] Mohammad Moradi and MohammadReza Keyvanpour. Captcha and its alternatives: A review. Security and Commu-\\nnication Networks , 8(12):2135–2156, 2015.\\n[33] Elie Bursztein, Steven Bethard, Celine Fabry, John C Mitchell, and Dan Jurafsky. How good are humans at solving\\ncaptchas? a large scale evaluation. In 2010 IEEE symposium on security and privacy , pages 399–413. IEEE, 2010.\\n[34] M Tariq Banday and Nisar A Shah. A study of captchas for securing web services. arXiv preprint arXiv:1112.5605 ,\\n2011.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 37}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:39\\n[35] L. Von Ahn and L. Dabbish. Labeling images with a computer game. In Proceedings of the SIGCHI conference on\\nHuman factors in computing systems , pages 319–326. ACM, 2004.\\n[36] Clark Pope and Khushpreet Kaur. Is it human or computer? defending e-commerce with captchas. IT professional ,\\n7(2):43–49, 2005.\\n[37] Nafisah Kheshaifaty and Adnan Gutub. Preventing multiple accessing attacks via efficient integration of captcha\\ncrypto hash functions. Int. J. Comput. Sci. Netw. Secur.(IJCSNS) , 20(9):16–28, 2020.\\n[38] Zhen Li and Qi Liao. Captcha: Machine or human solvers? a game-theoretical analysis. In 2018 5th IEEE International\\nConference on Cyber Security and Cloud Computing (CSCloud)/2018 4th IEEE International Conference on Edge Computing\\nand Scalable Cloud (EdgeCom) , pages 18–23. IEEE, 2018.\\n[39] Philippe Golle and Nicolas Ducheneaut. Preventing bots from playing online games. Computers in Entertainment\\n(CIE) , 3(3):3–3, 2005.\\n[40] Saikat Chakrabarti and Mukesh Singhal. Password-based authentication: Preventing dictionary attacks. Computer ,\\n40(6):68–74, 2007.\\n[41] Masoud Alajmi, Ibrahim Elashry, Hala S El-Sayed, and Osama S Faragallah. A password-based authentication system\\nbased on the captcha ai problem. IEEE Access , 2020.\\n[42] Altaf Khan and Alexander G Chefranov. A captcha-based graphical password with strong password space and\\nusability study. In 2020 International Conference on Electrical, Communication, and Computer Engineering (ICECCE) ,\\npages 1–6. IEEE, 2020.\\n[43] Manish Saxena, AK Usman, and S Hemant. Handling captcha free web-form spam with spamizer 1.1. In Proc. of the\\nInternational Conference on Computing for Sustainable Global Development , 2017.\\n[44] S Vaithyasubramanian, D Lalitha, and CK Kirubhashankar. Enhancing website security against bots, spam and web\\nattacks using l captcha. International Journal of Computers and Applications , pages 1–7, 2019.\\n[45] L. Von Ahn, M. Blum, and J. Langford. Telling humans and computers apart automatically. Communications of the\\nACM , 47(2):56–60, 2004.\\n[46] Donghoon Kim and Luke Sample. Search prevention with captcha against web indexing: A proof of concept. In 2019\\nIEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on\\nEmbedded and Ubiquitous Computing (EUC) , pages 219–224. IEEE, 2019.\\n[47] Pooja Kute, Tejaswini Lokhande, Manasi Kanadi, Sayali Kashid, and Ruchira Deshmukh. Video captcha as a graphical\\npassword. International Research Journal of Engineering and Technology (IRJET) , 5(03), 2018.\\n[48] M.T. Banday and NA Shah. A study of captchas for securing web services.\\n[49] Tejaswi Kumar, Navansh Goel, Siddhant Roy, and C Oswald. Usability evaluation of novel text captcha schemes\\nbased on colors and shapes. In International Conference on Innovative Computing and Communications , pages 355–363.\\nSpringer, 2022.\\n[50] J. Yan and A.S. El Ahmad. Breaking visual captchas with naive pattern recognition algorithms. In acsac , pages\\n279–291. IEEE Computer Society, 2007.\\n[51] G. Moy, N. Jones, C. Harkless, and R. Potter. Distortion estimation techniques in solving visual captchas. 2004.\\n[52] G. Mori and J. Malik. Recognizing objects in adversarial clutter: Breaking a visual captcha. 2003.\\n[53] Jeff Yan. A simple generic attack on text captchas. 2016.\\n[54] Guixin Ye, Zhanyong Tang, Dingyi Fang, Zhanxing Zhu, Yansong Feng, Pengfei Xu, Xiaojiang Chen, and Zheng\\nWang. Yet another text captcha solver: A generative adversarial network based approach. In Proceedings of the 2018\\nACM SIGSAC Conference on Computer and Communications Security , pages 332–348. ACM, 2018.\\n[55] Erkam Uzun, Simon Pak Ho Chung, Irfan Essa, and Wenke Lee. rtcaptcha: A real-time captcha based liveness detection\\nsystem. In Proceedings 2018 Network and Distributed System Security Symposium. doi , volume 10, 2018.\\n[56] Dileep George, Wolfgang Lehrach, Ken Kansky, Miguel Lázaro-Gredilla, Christopher Laan, Bhaskara Marthi, Xinghua\\nLou, Zhaoshi Meng, Yi Liu, Huayan Wang, et al. A generative vision model that trains with high data efficiency and\\nbreaks text-based captchas. Science , 358(6368):eaag2612, 2017.\\n[57] Rulin Shao, Zhouxing Shi, Jinfeng Yi, Pin-Yu Chen, and Cho-Jui Hsieh. Robust text captchas using adversarial\\nexamples. arXiv preprint arXiv:2101.02483 , 2021.\\n[58] Simon S Woo. Design and evaluation of 3d captchas. Computers & Security , 82:49–67, 2019.\\n[59] Xinyu Zhou, Cong Yao, He Wen, Yuzhi Wang, Shuchang Zhou, Weiran He, and Jiajun Liang. East: an efficient and\\naccurate scene text detector. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition , pages\\n5551–5560, 2017.\\n[60] Suzi Kim and Sunghee Choi. Dotcha: A 3d text-based scatter-type captcha. In International Conference on Web\\nEngineering , pages 238–252. Springer, 2019.\\n[61] Z. Lin and L. Wan. Style-preserving english handwriting synthesis. Pattern recognition , 40(7):2097–2109, 2007.\\n[62] M. Mori, A. Suzuki, A. Shio, and S. Ohtsuka. Generating new samples from handwritten numerals based on point\\ncorrespondence. In Proc. 7th Int. Workshop on Frontiers in Handwriting Recognition , pages 281–290, 2000.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 38}),\n",
       " Document(page_content='000:40 Noshina et al.\\n[63] Mohammad Tanvir Parvez and Suliman A Alsuhibany. Segmentation-validation based handwritten arabic captcha\\ngeneration. Computers & Security , page 101829, 2020.\\n[64] N. Arica and F.T. Yarman-Vural. An overview of character recognition focused on off-line handwriting. Systems, Man,\\nand Cybernetics, Part C: Applications and Reviews, IEEE Transactions on , 31(2):216–233, 2001.\\n[65] A.O. Thomas, A. Rusu, and V. Govindaraju. Synthetic handwritten captchas. Pattern Recognition , 42(12):3365–3373,\\n2009.\\n[66] Haichang Gao, Wei Wang, Jiao Qi, Xuqin Wang, Xiyang Liu, and Jeff Yan. The robustness of hollow captchas. In\\nProceedings of the 2013 ACM SIGSAC conference on Computer & communications security , pages 1075–1086. ACM, 2013.\\n[67] Jun Chen, Xiangyang Luo, Yanqing Guo, Yi Zhang, and Daofu Gong. A survey on breaking technique of text-based\\ncaptcha. Security and Communication Networks , 2017, 2017.\\n[68] M. Egele, L. Bilge, E. Kirda, and C. Kruegel. Captcha smuggling: hijacking web browsing sessions to create captcha\\nfarms. In Proceedings of the 2010 ACM Symposium on Applied Computing , pages 1865–1870. ACM, 2010.\\n[69] C Rama Krishna et al. Spiral captcha with adversarial perturbation and its security analysis with convolutional neural\\nnetwork. In Proceedings of Second Doctoral Symposium on Computational Intelligence , pages 67–83. Springer, 2022.\\n[70] M. Chew and J.D. Tygar. Image recognition captchas. Information Security , pages 268–279, 2004.\\n[71] O. Warner. Kittenauth, 2006.\\n[72] J. Elson, J.R. Douceur, J. Howell, and J. Saul. Asirra: a captcha that exploits interest-aligned manual image categorization.\\nCCS, 7:366–374.\\n[73] Prays Nikolay Aleksandrovich, Nikiforov Igor Alekseevich, Vladykin Maksim Vladimirovich, Nikiforov Aleksey\\nIgorevich, Prays Varvara Borisovna, and Nikiforova Olga Igorevna. Image-based captcha system, December 20 2012.\\nUS Patent App. 13/528,373.\\n[74] Bin Zhu, Jia Liu, Qiujie Li, Shipeng Li, and Ning Xu. Image-based captcha exploiting context in object recognition,\\nJuly 9 2013. US Patent 8,483,518.\\n[75] Gaurav Goswami, Brian M Powell, Mayank Vatsa, Richa Singh, and Afzel Noore. Facedcaptcha: Face detection based\\ncolor image captcha. Future Generation Computer Systems , 31:59–68, 2014.\\n[76] Anh Truong, Jeremy Goodsitt, Galen Rafferty, Vincent Pham, and Austin Walters. Generating captcha images using\\nvariations of the same object, April 7 2020. US Patent 10,614,207.\\n[77] Hyun Kwon, Hyunsoo Yoon, and Ki-Woong Park. Captcha image generation using style transfer learning in deep\\nneural network. In International Workshop on Information Security Applications , pages 234–246. Springer, 2019.\\n[78] Hyun Kwon, Hyunsoo Yoon, and Ki-Woong Park. Robust captcha image generation enhanced with adversarial\\nexample methods. IEICE TRANSACTIONS on Information and Systems , 103(4):879–882, 2020.\\n[79] M Poornananda Bhat and Rashmi Naveen Raj. Two-way image based captcha. In Advances in Communication, Signal\\nProcessing, VLSI, and Embedded Systems , pages 471–483. Springer, 2020.\\n[80] M. Xiaojuan, F. Christiane, and C. Perry. Semantic labeling of nonspeech audio clips. EURASIP Journal on Audio,\\nSpeech, and Music Processing , 2010, 2010.\\n[81] E. Bursztein and S. Bethard. Decaptcha: breaking 75% of ebay audio captchas. In Proceedings of the 3rd USENIX\\nconference on Offensive technologies , pages 8–8. USENIX Association, 2009.\\n[82] Jusop Choi, Taekkyung Oh, William Aiken, Simon S Woo, and Hyoungshick Kim. Poster: I can’t hear this because i\\nam human: A novel design of audio captcha system. In Proceedings of the 2018 on Asia Conference on Computer and\\nCommunications Security , pages 833–835, 2018.\\n[83] PL Chithra and K Sathya. Scanning-to-speech challenge-response authentication test for visually impaired. Computers\\n& Electrical Engineering , 92:107133, 2021.\\n[84] Chih-Hsiang Huang, Po-Hao Wu, Yi-Wen Liu, and Shan-Hung Wu. Attacking and defending behind a psychoacoustics-\\nbased captcha. In ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) ,\\npages 895–899. IEEE, 2021.\\n[85] M. Shirali-Shahreza and S. Shirali-Shahreza. Captcha for blind people. In Signal Processing and Information Technology,\\n2007 IEEE International Symposium on , pages 995–998. IEEE, 2007.\\n[86] G. Haichang, H. Liu, D. Yao, X. Liu, and U. Aickelin. An audio captcha to distinguish humans from computers. 2010.\\n[87] Valerie Fanelle, Sepideh Karimi, Aditi Shah, Bharath Subramanian, and Sauvik Das. Blind and human: Exploring\\nmore usable audio {CAPTCHA}designs. In Sixteenth Symposium on Usable Privacy and Security ( {SOUPS}2020) ,\\npages 111–125, 2020.\\n[88] Heemany Shekhar, Melody Moh, and Teng-Sheng Moh. Exploring adversaries to defend audio captcha. In 2019 18th\\nIEEE International Conference On Machine Learning And Applications (ICMLA) , pages 1155–1161. IEEE, 2019.\\n[89] R. Soni and D. Tiwari. Improved captcha method. International Journal of Computer Applications IJCA , 1(25):107–109,\\n2010.\\n[90] Divya Shankar, Prashant Gupta, and Aditya Jaiswal. Hybrid collage captcha. International journal of scientific &\\nengineering research , 4(1), 2013.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 39}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:41\\n[91] Tam V Nguyen, Zhe Huang, Saiteja Bethini, Venkata Sai Prasanth Ippagunta, and Phu H Phung. Secure captchas via\\nobject segment collages. IEEE Access , 8:84230–84238, 2020.\\n[92] A. Desai and P. Patadia. Drag and drop: A better approach to captcha. In India Conference (INDICON), 2009 Annual\\nIEEE, pages 1–4. IEEE.\\n[93] T. Giang and F. Liu. Mouse intervention captcha.\\n[94] H.S. Baird, M.A. Moll, and S.Y. Wang. A highly legible captcha that resists segmentation attacks. Human Interactive\\nProofs , pages 27–41, 2005.\\n[95] Farah Ruzanna Ridzuan, Hairulnizam Mahdin, Shahreen Kasim, Mohd Sanusi Azmi, et al. An image-based captcha\\nsystem using click. Acta Electronica Malaysia (AEM) , 3(1):23–25, 2019.\\n[96] E. Athanasopoulos and S. Antonatos. Enhanced captchas: Using animation to tell humans and computers apart. In\\nCommunications and Multimedia Security , pages 97–108. Springer, 2006.\\n[97] Zi Chu, Steven Gianvecchio, and Haining Wang. Bot or human? a behavior-based online bot detection system. In\\nFrom Database to Cyber Security , pages 432–449. Springer, 2018.\\n[98] Abdul Rouf Shah, M Tariq Banday, and Shafiya Afzal Sheikh. Design of a drag and touch multilingual universal\\ncaptcha challenge. In Advances in Computational Intelligence and Communication Technology , pages 381–393. Springer,\\n2021.\\n[99] Sanjay Sharma and Devendra Kumar. Highly secured intellectual graphical captcha. International Journal of Modern\\nEngineering & Management Research , 6(1), 2018.\\n[100] Bryan Cotta and Warren Benedetto. Game controller-based captcha, March 19 2019. US Patent 10,235,514.\\n[101] Philip Kirkbride, M Ali Akber Dewan, and Fuhua Lin. Game-like captchas for intrusion detection.\\n[102] Monther Aldwairi, Suaad Mohammed, and Megana Lakshmi Padmanabhan. Efficient and secure flash-based gaming\\ncaptcha. Journal of Parallel and Distributed Computing , 2020.\\n[103] Ramanpreet Kaur et al. A non ocr approach for math captcha design based on boolean algebra using digital gates to\\nenhance web security. In 2016 international conference on wireless communications, signal processing and networking\\n(WiSPNET) , pages 862–866. IEEE, 2016.\\n[104] M. Shirali-Shahreza and S. Shirali-Shahreza. Question-based captcha. In iccima , pages 54–58. IEEE Computer Society,\\n2007.\\n[105] Vincent Levesque. Haptic captcha, June 5 2018. US Patent 9,990,040.\\n[106] M. Blum, LA Von Ahn, J. Langford, and N. Hopper. The captcha project, completely automatic public turing test to\\ntell computers and humans apart. School of Computer Science, Carnegie-Mellon University, http://www. captcha. net .\\n[107] A.L. Coates, H.S. Baird, and RJ Faternan. Pessimal print: a reverse turing test. In Document Analysis and Recognition,\\n2001. Proceedings. Sixth International Conference on , pages 1154–1158. IEEE, 2001.\\n[108] Mohammad Hassan Shirali-Shahreza and Mohammad Shirali-Shahreza. Persian/arabic baffletext captcha. J. UCS ,\\n12(12):1783–1796, 2006.\\n[109] T.Y. Chan. Using a text-to-speech synthesizer to generate a reverse turing test. 2003.\\n[110] K.A. Kluever and R. Zanibbi. Balancing usability and security in a video captcha. In Proceedings of the 5th Symposium\\non Usable Privacy and Security , page 14. ACM, 2009.\\n[111] Hui Hu, Hao Fang, and LIU Qingyan. Captcha method and system, October 29 2013. US Patent 8,572,756.\\n[112] S.A. Ross, J.A. Halderman, and A. Finkelstein. Sketcha: a captcha based on line drawings of 3d models. In Proceedings\\nof the 19th international conference on World wide web , pages 821–830. ACM, 2010.\\n[113] B. Gooch, E. Reinhard, and A. Gooch. Human facial illustrations: Creation and psychophysical evaluation. ACM\\nTransactions on Graphics (TOG) , 23(1):27–44, 2004.\\n[114] R. Gossweiler, M. Kamvar, and S. Baluja. What’s up captcha?: a captcha based on image orientation. In Proceedings of\\nthe 18th international conference on World wide web , pages 841–850. ACM, 2009.\\n[115] C.J. Ho, C.C. Wu, K.T. Chen, and C.L. Lei. Deviltyper: a game for captcha usability evaluation. Computers in\\nEntertainment (CIE) , 9(1):3, 2011.\\n[116] Manar Mohamed, Song Gao, Nitesh Saxena, and Chengcui Zhang. Dynamic cognitive game captcha usability and\\ndetection of streaming-based farming. In the Workshop on Usable Security (USEC), co-located with NDSS , 2014.\\n[117] Arun Pratap Singh, Sanjay Sharma, and Vaishali Singh. Hybrid text illusion captcha dealing with partial vision\\ncertainty. In Social Networking and Computational Intelligence , pages 687–696. Springer, 2020.\\n[118] Xiang Li, Yuzheng Chen, Rakesh Patibanda, and Florian’Floyd’ Mueller. vrcaptcha: Exploring captcha designs in\\nvirtual reality. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems , pages 1–4,\\n2021.\\n[119] Chenghui Shi, Xiaogang Xu, Shouling Ji, Kai Bu, Jianhai Chen, Raheem Beyah, and Ting Wang. Adversarial captchas.\\nIEEE Transactions on Cybernetics , 2021.\\n[120] S. Saklikar and S. Saha. Public key-embedded graphic captchas. In Consumer Communications and Networking\\nConference, 2008. CCNC 2008. 5th IEEE , pages 262–266. IEEE.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 40}),\n",
       " Document(page_content='000:42 Noshina et al.\\n[121] M Hassan Shirali-Shahreza and Mohammad Shirali-Shahreza. Localized captcha for illiterate people. In 2007\\nInternational Conference on Intelligent and Advanced Systems , pages 675–679. IEEE, 2007.\\n[122] Jonathan Holman, Jonathan Lazar, Jinjuan Heidi Feng, and John D’Arcy. Developing usable captchas for blind users.\\nInProceedings of the 9th international ACM SIGACCESS conference on Computers and accessibility , pages 245–246.\\nACM, 2007.\\n[123] Amalia I Rusu, Rebecca Docimo, and Adrian Rusu. Leveraging cognitive factors in securing www with captcha. In\\nWebApps , 2010.\\n[124] Narges Roshanbin and James Miller. Enhancing captcha security using interactivity, dynamism, and mouse movement\\npatterns. International Journal of Systems and Service-Oriented Engineering (IJSSOE) , 6(1):17–36, 2016.\\n[125] Avinash Kalgi, Matthew Ward-Steinman, and Qian Wang. Mobile human challenge-response test, April 21 2015. US\\nPatent 9,015,804.\\n[126] Mohammad Shirali-Shahreza. Highlighting captcha. In 2008 Conference on Human System Interactions , pages 247–250.\\nIEEE, 2008.\\n[127] Sajad Shirali-Shahreza and Mohammad Shirali-Shahreza. Multilingual highlighting captcha. In 2011 Eighth Interna-\\ntional Conference on Information Technology: New Generations , pages 447–452. IEEE, 2011.\\n[128] Rosa Lin, Shih-Yu Huang, Graeme B Bell, and Yeuan-Kuen Lee. A new captcha interface design for mobile devices. In\\nProceedings of the Twelfth Australasian User Interface Conference-Volume 117 , pages 3–8. Australian Computer Society,\\nInc., 2011.\\n[129] Sajad Shirali-Shahreza, Gerald Penn, Ravin Balakrishnan, and Yashar Ganjali. Seesay and hearsay captcha for mobile\\ninteraction. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 2147–2156. ACM,\\n2013.\\n[130] Ahmed Iqbal Pritom, Mehrab Zaman Chowdhury, Joy Protim, Shanto Roy, Md Rashedur Rahman, and Sadia Mehnaz\\nPromi. Combining movement model with finger-stroke level model towards designing a security enhancing mobile\\nfriendly captcha. In Proceedings of the 2020 9th International Conference on Software and Computer Applications , pages\\n351–356, 2020.\\n[131] Alejandro Acien, Aythami Morales, Julian Fierrez, Ruben Vera-Rodriguez, and Oscar Delgado-Mohatar. Becaptcha: Bot\\ndetection in smartphone interaction using touchscreen biometrics and mobile sensors. arXiv preprint arXiv:2005.13655 ,\\n2020.\\n[132] Kentaro Aburada, Shotaro Usuzaki, Hisaaki Yamaba, Tetsuro Katayama, Masayuki Mukunoki, Mirang Park, and\\nNaonobu Okazaki. Implementation of captcha suitable for mobile devices. IEICE Communications Express , 2019.\\n[133] Shakila Lehan Perera. oCAPTCHA-Enhanced CAPTCHA Method using Image Orientation . PhD thesis, 2019.\\n[134] Alejandro Acien, Aythami Morales, Julian Fierrez, Ruben Vera-Rodriguez, and Ivan Bartolome. Be-captcha: Detecting\\nhuman behavior in smartphone interaction using multiple inbuilt sensors. arXiv preprint arXiv:2002.00918 , 2020.\\n[135] Alejandro Acien, Aythami Morales, Julian Fierrez, Ruben Vera-Rodriguez, and Oscar Delgado-Mohatar. Becaptcha:\\nBehavioral bot detection using touchscreen and mobile sensors benchmarked on humidb. Engineering Applications of\\nArtificial Intelligence , 98:104058, 2021.\\n[136] Sajad Shirali-Shahreza and Mohammad Shirali-Shahreza. A new human interactive proofs system for deaf persons.\\nInFifth International Conference on Information Technology: New Generations (itng 2008) , pages 807–810. IEEE, 2008.\\n[137] Sajad Shirali-Shahreza and Mohammad Shirali-Shahreza. Captcha for children. In 2008 IEEE International Conference\\non System of Systems Engineering , pages 1–6. IEEE, 2008.\\n[138] Sheena Mohammed, D Madhuri Dachepally, and A Angel Mary. 3c-click, count, captcha graphical password technique.\\nResearch Journal of Engineering and Technology , 9(2):189–194, 2018.\\n[139] Altaf Khan and Alexander G Chefranov. A new secure and usable captcha-based graphical password scheme. In\\nInternational Symposium on Computer and Information Sciences , pages 150–157. Springer, 2018.\\n[140] Shikhar Singh Patel, Akarsh Jaiswal, Yash Arora, and Bharti Sharma. Survey on graphical password authentication\\nsystem. Data Intelligence and Cognitive Informatics , pages 699–708, 2021.\\n[141] Ahmad Salah El Ahmad, Jeff Yan, and Wai-Yin Ng. Captcha design: Color, usability, and security. IEEE Internet\\nComputing , 16(2):44–51, 2011.\\n[142] Chenghui Shi, Shouling Ji, Qianjun Liu, Changchang Liu, Yuefeng Chen, Yuan He, Z Liu, R Beyah, and T Wang.\\nText captcha is dead? a large scale deployment and empirical study. In The 27th ACM Conference on Computer and\\nCommunications Security , 2020.\\n[143] Darko Brodić and Alessia Amelio. Captcha programming. In The CAPTCHA: Perspectives and Challenges , pages 55–76.\\nSpringer, 2020.\\n[144] M Noorjahan. A bio metric based approach for using captcha–to enhance accessibility for the visually impaired.\\nDisability and Rehabilitation: Assistive Technology , 2019.\\n[145] Narges Roshanbin and James Miller. Adamas: Interweaving unicode and color to enhance captcha security. Future\\nGeneration Computer Systems , 55:289–310, 2016.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 41}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:43\\n[146] Jeffrey P Bigham and Anna C Cavender. Evaluating existing audio captchas and an interface optimized for non-visual\\nuse. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 1829–1838, 2009.\\n[147] Huy D Truong, Christopher F Turner, and Cliff C Zou. icaptcha: the next generation of captcha designed to defend\\nagainst 3rd party human attacks. In 2011 IEEE International Conference on Communications (ICC) , pages 1–6. IEEE,\\n2011.\\n[148] Song Gao, Manar Mohamed, Nitesh Saxena, and Chengcui Zhang. Gaming the game: Defeating a game captcha with\\nefficient and robust hybrid attacks. In 2014 IEEE International Conference on Multimedia and Expo (ICME) , pages 1–6.\\nIEEE, 2014.\\n[149] Rudy Berton, Ombretta Gaggi, Agnieszka Kolasinska, Claudio Enrico Palazzi, and Giacomo Quadrio. Are captchas\\npreventing robotic intrusion or accessibility for impaired users? In 2020 IEEE 17th Annual Consumer Communications\\n& Networking Conference (CCNC) , pages 1–6. IEEE, 2020.\\n[150] Lourdes Moreno, María González, and Paloma Martínez. Captcha and accessibility-is this the best we can do?. In\\nWEBIST (2) , pages 115–122, 2014.\\n[151] Mohammed Mujeeb Kaladgi and Jameel Ahmed Kaladgi. Applying a partial captcha, July 16 2019. US Patent 10,354,060.\\n[152] Me Jakeera Begum and M Venkata Rao. Collaborative tagging using captcha. International Journal of Innovative\\nTechnology And Research, Volume , (3):2436–2439, 2015.\\n[153] Daniel Lopresti. Leveraging the captcha problem. In International Workshop on Human Interactive Proofs , pages\\n97–110. Springer, 2005.\\n[154] Luis Von Ahn, Benjamin Maurer, Colin McMillen, David Abraham, and Manuel Blum. recaptcha: Human-based\\ncharacter recognition via web security measures. Science , 321(5895):1465–1468, 2008.\\n[155] Haichang Gao, Honggang Liu, Dan Yao, Xiyang Liu, and Uwe Aickelin. An audio captcha to distinguish humans from\\ncomputers. In 2010 Third International Symposium on Electronic Commerce and Security , pages 265–269. IEEE, 2010.\\n[156] Triet Giang, Fei Liu, et al. Mouse intervention captcha. In iiWAS , pages 155–162, 2006.\\n[157] Henry S Baird, Allison L Coates, and Richard J Fateman. Pessimalprint: a reverse turing test. International Journal on\\nDocument Analysis and Recognition , 5(2-3):158–163, 2003.\\n[158] T Kalaichelvi and P Apuroop. Image steganography method to achieve confidentiality using captcha for authentication.\\nIn2020 5th International Conference on Communication and Electronics Systems (ICCES) , pages 495–499. IEEE, 2020.\\n[159] Ye Wang and Mi Lu. An optimized system to solve text-based captcha. arXiv preprint arXiv:1806.07202 , 2018.\\n[160] K. Chellapilla and P. Simard. Using machine learning to break visual human interaction proofs (hips). Advances in\\nNeural Information Processing Systems , 17, 2004.\\n[161] A.S. El Ahmad, J. Yan, and L. Marshall. The robustness of a new captcha. In Proceedings of the Third European\\nWorkshop on System Security , pages 36–41. ACM, 2010.\\n[162] Bin B Zhu, Jeff Yan, Qiujie Li, Chao Yang, Jia Liu, Ning Xu, Meng Yi, and Kaiwei Cai. Attacks and design of image\\nrecognition captchas. In Proceedings of the 17th ACM conference on Computer and communications security , pages\\n187–200, 2010.\\n[163] S.Y. Huang, Y.K. Lee, G. Bell, and Z. Ou. A projection-based segmentation algorithm for breaking msn and yahoo\\ncaptchas. In Proceedings of the World Congress on Engineering , volume 1. Citeseer, 2008.\\n[164] K. Chellapilla, K. Larson, P. Simard, and M. Czerwinski. Computers beat humans at single character recognition in\\nreading based human interaction proofs (hips). In Proceedings of the Second Conference on Email and Anti-Spam , pages\\n21–22. Citeseer, 2005.\\n[165] W. Walker, P. Lamere, P. Kwok, B. Raj, R. Singh, E. Gouvea, P. Wolf, and J. Woelfel. Sphinx-4: A flexible open source\\nframework for speech recognition. Sun Microsystems, Inc. Mountain View, CA, USA , page 18, 2004.\\n[166] S. Li, S. Shah, M. Khan, S.A. Khayam, A.R. Sadeghi, and R. Schmitz. Breaking e-banking captchas. In Proceedings of\\nthe 26th Annual Computer Security Applications Conference , pages 171–180. ACM, 2010.\\n[167] Philippe Golle. Machine learning attacks against the asirra captcha. In Proceedings of the 15th ACM conference on\\nComputer and communications security , pages 535–542, 2008.\\n[168] Renu Saroha and Sumeet Gill. Strengthening pix captcha using trainlm function in backpropagation. In Rising Threats\\nin Expert Applications and Solutions , pages 679–686. Springer, 2021.\\n[169] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural\\nnetworks. In Advances in neural information processing systems , pages 1097–1105, 2012.\\n[170] Haiqin Weng, Binbin Zhao, Shouling Ji, Jianhai Chen, Ting Wang, Qinming He, and Raheem Beyah. Towards\\nunderstanding the security of modern image captchas and underground captcha-solving services. Big Data Mining\\nand Analytics , 2(2):118–144, 2019.\\n[171] Feng-Lin Du, Jia-Xing Li, Zhi Yang, Peng Chen, Bing Wang, and Jun Zhang. Captcha recognition based on faster\\nr-cnn. In International Conference on Intelligent Computing , pages 597–605. Springer, 2017.\\n[172] Kaixuan Liu, Rong Zhang, and Ke Qing. Cnn for breaking text-based captcha with noise. In Ninth International\\nConference on Digital Image Processing (ICDIP 2017) , volume 10420, page 104202V. International Society for Optics and\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 42}),\n",
       " Document(page_content='000:44 Noshina et al.\\nPhotonics, 2017.\\n[173] Sumeet Sachdev. Breaking captcha characters using multi-task learning cnn and svm. In 2020 4th International\\nConference on Computational Intelligence and Networks (CINE) , pages 1–6. IEEE, 2020.\\n[174] Yujin Shu and Yongjin Xu. End-to-end captcha recognition using deep cnn-rnn network. In 2019 IEEE 3rd Advanced\\nInformation Management, Communicates, Electronic and Automation Control Conference (IMCEC) , pages 54–58. IEEE,\\n2019.\\n[175] Yang Jia, Wang Fan, Chen Zhao, and Jungang Han. An approach for chinese character captcha recognition using cnn.\\nInJournal of Physics: Conference Series , volume 1087, 2018.\\n[176] Stephen Dankwa and Lu Yang. An efficient and accurate depth-wise separable convolutional neural network for\\ncybersecurity vulnerability assessment based on captcha breaking. Electronics , 10(4):480, 2021.\\n[177] Ondrej Bostik, Karel Horak, Lukas Kratochvila, Tomas Zemcik, and Simon Bilik. Semi-supervised deep learning\\napproach to break common captchas. Neural Computing and Applications , pages 1–11, 2021.\\n[178] Jun Chen, Xiangyang Luo, Jianwei Hu, Dengpan Ye, and Daofu Gong. An attack on hollow captcha using accurate\\nfilling and nonredundant merging. IETE Technical Review , 35(sup1):106–118, 2018.\\n[179] Jun Chen, Xiangyang Luo, Yingying Liu, Jinwei Wang, and Yuanyuan Ma. Selective learning confusion class for\\ntext-based captcha recognition. IEEE Access , 7:22246–22259, 2019.\\n[180] Ajeet Singh, Vikas Tiwari, and Appala Naidu Tentu. A machine vision attack model on image based captchas challenge:\\nLarge scale evaluation. In International Conference on Security, Privacy, and Applied Cryptography Engineering , pages\\n52–64. Springer, 2018.\\n[181] Xiaohui Zhang, Xinhua Liu, Thompson Sarkodie-Gyan, and Zhixiong Li. Development of a character captcha\\nrecognition system for the visually impaired community using deep learning. Machine Vision and Applications ,\\n32(1):1–19, 2021.\\n[182] Zhong Wang and Peibei Shi. Captcha recognition method based on cnn with focal loss. Complexity , 2021, 2021.\\n[183] Tommi Vatanen, Tapani Raiko, Harri Valpola, and Yann LeCun. Pushing stochastic gradient towards second-order\\nmethods–backpropagation learning with transformations in nonlinearities. In International Conference on Neural\\nInformation Processing , pages 442–449. Springer, 2013.\\n[184] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings\\nof the IEEE conference on computer vision and pattern recognition , pages 770–778, 2016.\\n[185] Ian J Goodfellow, Yaroslav Bulatov, Julian Ibarz, Sacha Arnoud, and Vinay Shet. Multi-digit number recognition from\\nstreet view imagery using deep convolutional neural networks. arXiv preprint arXiv:1312.6082 , 2013.\\n[186] Zhang Liang, Huang ShuGuang, and Shi Zhaoxiang. A highly reliable captcha recognition algorithm based on\\nrejection. Acta Automatica Sinica , 37(7):891–900, 2011.\\n[187] Mengyun Tang, Haichang Gao, Yang Zhang, Yi Liu, Ping Zhang, and Ping Wang. Research on deep learning techniques\\nin breaking text-based captchas and designing image-based captcha. IEEE Transactions on Information Forensics and\\nSecurity , 13(10):2522–2537, 2018.\\n[188] Suphannee Sivakorn, Iasonas Polakis, and Angelos D Keromytis. I am robot:(deep) learning to break semantic image\\ncaptchas. In 2016 IEEE European Symposium on Security and Privacy (EuroS&P) , pages 388–403. IEEE, 2016.\\n[189] Gidudu Anthony, Hulley Greg, and Marwala Tshilidzi. Classification of images using support vector machines. arXiv\\npreprint arXiv:0709.3967 , 2007.\\n[190] Oleg Starostenko, Claudia Cruz-Perez, Fernando Uceda-Ponga, and Vicente Alarcon-Aquino. Breaking text-based\\ncaptchas with variable word and character orientation. Pattern Recognition , 48(4):1101–1112, 2015.\\n[191] Haichang Gao, Wei Wang, and Ye Fan. Divide and conquer: an efficient attack on yahoo! captcha. In 2012 IEEE 11th\\nInternational Conference on Trust, Security and Privacy in Computing and Communications , pages 9–16. IEEE, 2012.\\n[192] Manuel J Fonseca and Joaquim A Jorge. Using fuzzy logic to recognize geometric shapes interactively. In Ninth IEEE\\nInternational Conference on Fuzzy Systems. FUZZ-IEEE 2000 (Cat. No. 00CH37063) , volume 1, pages 291–296. IEEE,\\n2000.\\n[193] Joseph o’Rourke. Computational geometry in C . Cambridge university press, 1998.\\n[194] Sreela Sasi and Jatinder Singh Bedi. Handwritten character recognition using fuzzy logic. In Proceedings of 1994 37th\\nMidwest Symposium on Circuits and Systems , volume 2, pages 1399–1402. IEEE, 1994.\\n[195] Rabih Al Nachar, Elie Inaty, Patrick J Bonnin, and Yasser Alayli. Breaking down captcha using edge corners and fuzzy\\nlogic segmentation/recognition technique. Security and Communication Networks , 8(18):3995–4012, 2015.\\n[196] Patrice Y Simard, David Steinkraus, John C Platt, et al. Best practices for convolutional neural networks applied to\\nvisual document analysis. In Icdar , volume 3, 2003.\\n[197] Alessandro L Koerich, Robert Sabourin, and Ching Y Suen. Recognition and verification of unconstrained handwritten\\nwords. IEEE Transactions on Pattern Analysis and Machine Intelligence , 27(10):1509–1522, 2005.\\n[198] Gaganjot Kaur and Monika Aggarwal. Artificial intelligent system for character recognition using levenberg-\\nmarquardt algorithm. International Journal of Advanced Research in Computer Science and Software Engineering ,\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 43}),\n",
       " Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues, Challenges, and Future Research Directions 000:45\\n2(5):220–223, 2012.\\n[199] Sameeksha Barve. Optical character recognition using artificial neural network. International Journal of Advanced\\nResearch in Computer Engineering & Technology , 1(4):131–133, 2012.\\n[200] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial\\nnetworks. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 1125–1134, 2017.\\n[201] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-\\nconsistent adversarial networks. In Proceedings of the IEEE international conference on computer vision , pages 2223–2232,\\n2017.\\n[202] Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. Seqgan: Sequence generative adversarial nets with policy gradient.\\nInThirty-First AAAI Conference on Artificial Intelligence , 2017.\\n[203] Jiwei Li, Will Monroe, Tianlin Shi, Sébastien Jean, Alan Ritter, and Dan Jurafsky. Adversarial learning for neural\\ndialogue generation. arXiv preprint arXiv:1701.06547 , 2017.\\n[204] Noshina Tariq, Muhammad Asim, Feras Al-Obeidat, Muhammad Zubair Farooqi, Thar Baker, Mohammad Hammoudeh,\\nand Ibrahim Ghafir. The security of big data in fog-enabled iot applications including blockchain: A survey. Sensors ,\\n19(8):1788, 2019.\\n[205] A. Hindle, M.W. Godfrey, and R.C. Holt. Reverse engineering captchas. In 2008 15th Working Conference on Reverse\\nEngineering , pages 59–68. IEEE, 2008.\\n[206] Kyle Adams. Detecting and breaking captcha automation scripts and preventing image scraping, December 29 2015.\\nUS Patent 9,223,997.\\n[207] Yang-Wai Chow, Willy Susilo, and Pairat Thorncharoensri. CAPTCHA Design and Security Issues , pages 69–92.\\nSpringer Singapore, 2019.\\n[208] Yujia Sun and Jan Platoš. Captcha recognition based on kohonen maps. In International Conference on Intelligent\\nNetworking and Collaborative Systems , pages 296–305. Springer, 2019.\\n[209] Li Wei, Xiang Li, TingRong Cao, Quan Zhang, LiangQi Zhou, and WenLi Wang. Research on optimization of captcha\\nrecognition algorithm based on svm. In Proceedings of the 2019 11th International Conference on Machine Learning and\\nComputing , pages 236–240, 2019.\\n[210] Ms Mrunali S Sonwalkar. Captcha: Novel approach to secure user. Pramana Research Journal , 10(1):106–114, 2020.\\n[211] Fatmah H Alqahtani and Fawaz A Alsulaiman. Is image-based captcha secure against attacks based on machine\\nlearning? an experimental study. Computers & Security , 88:101635, 2020.\\n[212] Yang Zi, Haichang Gao, Zhouhang Cheng, and Yi Liu. An end-to-end attack on text captchas. IEEE Transactions on\\nInformation Forensics and Security , 15:753–766, 2019.\\n[213] Chunhui Li, Xingshu Chen, Haizhou Wang, Yu Zhang, and Peiming Wang. An end-to-end attack on text-based\\ncaptchas based on cycle-consistent generative adversarial network. arXiv preprint arXiv:2008.11603 , 2020.\\n[214] Wen-Bo Zhao, De-Shuang Huang, Ji-Yan Du, and Li-Ming Wang. Genetic optimization of radial basis probabilistic\\nneural networks. International Journal of Pattern Recognition and Artificial Intelligence , 18(08):1473–1499, 2004.\\n[215] Zhong-Qiu Zhao, Peng Zheng, Shou-tao Xu, and Xindong Wu. Object detection with deep learning: A review. IEEE\\ntransactions on neural networks and learning systems , 30(11):3212–3232, 2019.\\n[216] Zhong-Qiu Zhao, Yiu-ming Cheung, Haibo Hu, and Xindong Wu. Corrupted and occluded face recognition via\\ncooperative sparse representation. Pattern Recognition , 56:77–87, 2016.\\n[217] Xiao-Feng Wang, De-Shuang Huang, Ji-Xiang Du, Huan Xu, and Laurent Heutte. Classification of plant leaf images\\nwith complicated background. Applied mathematics and computation , 205(2):916–926, 2008.\\n[218] Yang Zhao, De-Shuang Huang, and Wei Jia. Completed local binary count for rotation invariant texture classification.\\nIEEE transactions on image processing , 21(10):4492–4497, 2012.\\n[219] Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and Lawrence D\\nJackel. Backpropagation applied to handwritten zip code recognition. Neural computation , 1(4):541–551, 1989.\\n[220] K He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016 ieee conference on computer vision and pattern recognition\\n(cvpr). IEEE Las Vegas, USA, 2016.\\n[221] Margarita Osadchy, Julio Hernandez-Castro, Stuart J Gibson, Orr Dunkelman, and Daniel Pérez-Cabo. No bot expects\\nthe deepcaptcha! introducing immutable adversarial examples with applications to captcha. IACR Cryptol. ePrint\\nArch. , 2016:336, 2016.\\n[222] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus.\\nIntriguing properties of neural networks. arXiv preprint arXiv:1312.6199 , 2013.\\n[223] Margarita Osadchy, Julio Hernandez-Castro, Stuart Gibson, Orr Dunkelman, and Daniel Pérez-Cabo. No bot expects the\\ndeepcaptcha! introducing immutable adversarial examples, with applications to captcha generation. IEEE Transactions\\non Information Forensics and Security , 12(11):2640–2653, 2017.\\n[224] Carlos Hernández-Castro, David F Barrero, and Maria Dolores R-Moreno. Breaking captchastar using the basecass\\nmethodology. ACM Transactions on Internet Technology , 23(1):1–12, 2023.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 44}),\n",
       " Document(page_content='000:46 Noshina et al.\\n[225] Amine Ben Slama, Hanene Sahli, Aymen Mouelhi, Jihene Marrakchi, Mounir Sayadi, and Hedi Trabelsi. Dbn-dnn:\\ndiscrimination and classification of vng sequence using deep neural network framework in the emd domain. Computer\\nMethods in Biomechanics and Biomedical Engineering: Imaging & Visualization , pages 1–10, 2020.\\n[226] Nan Li, Qianyi Jiang, Qi Song, Rui Zhang, and Xiaolin Wei. Alec: An accurate, light and efficient network for captcha\\nrecognition. In International Workshop on Document Analysis Systems , pages 60–73. Springer, 2020.\\n[227] Burak Uzkent, Christopher Yeh, and Stefano Ermon. Efficient object detection in large images using deep reinforcement\\nlearning. In The IEEE Winter Conference on Applications of Computer Vision , pages 1824–1833, 2020.\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 45})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='CAPTCHA Types and Breaking Techniques: Design Issues,\\nChallenges, and Future Research Directions\\nNOSHINA TARIQ, Department of Avionics Engineering, Air University, Pakistan\\nFARRUKH ASLAM KHAN∗,Center of Excellence in Information Assurance, King Saud University, Saudi\\nArabia\\nSYED ATIF MOQURRAB, School of Computing, Gachon University, South Korea\\nGAUTAM SRIVASTAVA, Brandon University, Canada\\nThe proliferation of the Internet and mobile devices has resulted in malicious bots’ access to genuine resources\\nand data. Bots may instigate phishing, unauthorized access, denial-of-service, and spoofing attacks, to mention\\na few. Authentication and testing mechanisms to verify the end-users and prohibit malicious programs from\\ninfiltrating the services and data are strong defense systems against malicious bots. Completely Automated\\nPublic Turing test to tell Computers and Humans Apart (CAPTCHA) is an authentication process to confirm', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 0}),\n",
       " Document(page_content='Public Turing test to tell Computers and Humans Apart (CAPTCHA) is an authentication process to confirm\\nthat the user is a human; hence, access is granted. This paper provides an in-depth survey on CAPTCHAs and\\nfocuses on two main things: (1) a detailed discussion on various CAPTCHA types along with their advantages,\\ndisadvantages, and design recommendations, and (2) an in-depth analysis of different CAPTCHA breaking\\ntechniques. The survey is based on over two hundred studies on the subject matter conducted since 2003 to\\ndate. The analysis reinforces the need to design more attack-resistant CAPTCHAs while keeping their usability\\nintact. The paper also highlights the design challenges and open issues related to CAPTCHAs. Furthermore, it\\nalso provides useful recommendations for breaking CAPTCHAs.\\nCCS Concepts: •CAPTCHA ;•CAPTCHA types ;•CAPTCHA breaking techniques ;\\nACM Reference Format:\\nNoshina Tariq, Farrukh Aslam Khan, Syed Atif Moqurrab, and Gautam Srivastava. 2023. CAPTCHA Types', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 0}),\n",
       " Document(page_content='CCS Concepts: •CAPTCHA ;•CAPTCHA types ;•CAPTCHA breaking techniques ;\\nACM Reference Format:\\nNoshina Tariq, Farrukh Aslam Khan, Syed Atif Moqurrab, and Gautam Srivastava. 2023. CAPTCHA Types\\nand Breaking Techniques: Design Issues, Challenges, and Future Research Directions. ACM Comput. Surv. 00,\\n0, Article 000 (February 2023), 46 pages. https://doi.org/10.1145/1122445.1122456\\n1 INTRODUCTION\\nThe Internet is a primary mode of communication in the modern age of the Internet of Things\\n(IoT) [ 1]. The availability of a diverse range of mobile devices and more affordable high-speed data\\nsubscriptions boosted consumers’ interest in Internet use. From its inception, Internet security\\nhas been the primary concern of web developers. As the Internet continues to grow for providing\\nvarious websites, services, and blogs likewise grow. Today’s websites are dedicated to the public,\\ntransportation, entertainment, financial services, food items, healthcare, and hotel reservations, to', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 0}),\n",
       " Document(page_content='transportation, entertainment, financial services, food items, healthcare, and hotel reservations, to\\nmention a few. In this regard, the growing user base also necessitates the deployment of high-end\\ncomputing power at the websites [ 2]. However, these high-end processors are rendered ineffective\\nAuthors’ addresses: Noshina Tariq, noshina.tariq@mail.au.edu.pkDepartment of Avionics Engineering,, Air University,\\nService Road E-9/E-8, Islamabad, Pakistan; Farrukh Aslam KhanCenter of Excellence in Information Assurance,, King\\nSaud University, P.O. Box 92144, Riyadh, 11653, Saudi Arabia, fakhan@ksu.edu.sa; Syed Atif Moqurrab, atif@gachon.ac.kr,\\nSchool of Computing, Gachon University, 1342, Seongnam-daero, Sujeong-gu, Seongnam-si, 13120, Seongnam, South Korea;\\nGautam Srivastava, srivastavag@brandonu.ca, Brandon University, Brandon, MB R7A 6A9,, Brandon, Canada.\\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 0}),\n",
       " Document(page_content='Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\\nthe full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.\\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\\n©2018 Association for Computing Machinery.\\n0360-0300/2023/2-ART000 $15.00\\nhttps://doi.org/10.1145/1122445.1122456\\nACM Comput. Surv., Vol. 00, No. 0, Article 000. Publication date: February 2023.arXiv:2307.10239v1  [cs.CR]  16 Jul 2023', metadata={'source': 'CAPTCHATypesandBreaking TechniquesDesign Issues.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=splitter.split_documents(text_document)\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"upgrade\"\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LangSmithRetrieverParams' from 'langchain_core.retrievers' (c:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_core\\retrievers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupgrade langchain_community\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcohere\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m      5\u001b[0m cohere_client \u001b[38;5;241m=\u001b[39m cohere\u001b[38;5;241m.\u001b[39mClient(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcohere_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      6\u001b[0m db \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(documents[:\u001b[38;5;241m15\u001b[39m], cohere_client\u001b[38;5;241m.\u001b[39membed())\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_community\\vectorstores\\__init__.py:488\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _module_lookup:\n\u001b[1;32m--> 488\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_module_lookup\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xor_args\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStore\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maximal_marginal_relevance\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_core\\vectorstores\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VST, VectorStore, VectorStoreRetriever\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01min_memory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryVectorStore\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorStore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorStoreRetriever\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInMemoryVectorStore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigDict, Field, model_validator\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRetriever, LangSmithRetrieverParams\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_in_executor\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LangSmithRetrieverParams' from 'langchain_core.retrievers' (c:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_core\\retrievers.py)"
     ]
    }
   ],
   "source": [
    "%pip upgrade langchain_community\n",
    "import cohere\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "cohere_client = cohere.Client(os.getenv(\"cohere_api_key\"))\n",
    "db = Chroma.from_documents(documents[:15], cohere_client.embed())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "%pip list | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LangSmithRetrieverParams' from 'langchain_core.retrievers' (c:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_core\\retrievers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRetriever\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_community\\vectorstores\\__init__.py:488\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _module_lookup:\n\u001b[1;32m--> 488\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_module_lookup\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xor_args\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStore\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maximal_marginal_relevance\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_core\\vectorstores\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VST, VectorStore, VectorStoreRetriever\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01min_memory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryVectorStore\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorStore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorStoreRetriever\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInMemoryVectorStore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_core\\vectorstores\\base.py:42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigDict, Field, model_validator\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRetriever, LangSmithRetrieverParams\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_in_executor\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LangSmithRetrieverParams' from 'langchain_core.retrievers' (c:\\Users\\shawn\\OneDrive\\Desktop\\genai\\venv\\lib\\site-packages\\langchain_core\\retrievers.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.retrievers import BaseRetriever, LangSmithRetrieverParams\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
